{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69bb700-cfea-4a65-9923-567f570bf6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # CBC Multi-Output (v2) — LINEAR (Ridge) — HGB, HCT, RBC\n",
    "#\n",
    "# - Usa el dataset: cbc_synthetic_30000_enriched_v2.csv\n",
    "# - Elimina features fuertemente correlacionadas (|corr| > 0.80) antes de entrenar\n",
    "# - Entrena modelo multi-output y modelos single-output (lineales)\n",
    "# - Calcula SHAP (LinearExplainer + masker)\n",
    "# - Usa nombres \"bonitos\" para features y outputs en tablas y gráficos\n",
    "# - Mide tiempo y memoria de entrenamiento y SHAP (multi vs single-output)\n",
    "#   - Memoria medida como TOTAL PEAK en MB (decimal), NO delta.\n",
    "\n",
    "# %%\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import shap\n",
    "from memory_profiler import memory_usage  # devuelve MiB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge  # modelo lineal estable (multioutput nativo)\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Directorios base\n",
    "# -----------------------------\n",
    "BASE_DIR = Path(\".\")\n",
    "OUT_DIR  = BASE_DIR / \"cbc_multi_output_v2_outputs_time_memory_MB_05_linear_ridge\"\n",
    "IMG_DIR  = OUT_DIR / \"figs\"\n",
    "TAB_DIR  = OUT_DIR / \"tables\"\n",
    "\n",
    "for d in [OUT_DIR, IMG_DIR, TAB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _safe_stem(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Evita caracteres problemáticos en Windows para nombres de archivo.\n",
    "    \"\"\"\n",
    "    bad = '<>:\"/\\\\|?*'\n",
    "    for ch in bad:\n",
    "        s = s.replace(ch, \"_\")\n",
    "    return s\n",
    "\n",
    "def save_current_fig(path_no_ext: Path):\n",
    "    \"\"\"\n",
    "    Guarda la figura actual en .png y .pdf.\n",
    "    - En Windows a veces el PDF queda corrupto si no se fuerza format o no se cierra la figura.\n",
    "    \"\"\"\n",
    "    path_no_ext = Path(path_no_ext)\n",
    "    png_path = path_no_ext.with_suffix(\".png\")\n",
    "    pdf_path = path_no_ext.with_suffix(\".pdf\")\n",
    "\n",
    "    plt.savefig(png_path, bbox_inches=\"tight\", dpi=300, format=\"png\")\n",
    "    plt.savefig(pdf_path, bbox_inches=\"tight\", dpi=300, format=\"pdf\")\n",
    "\n",
    "def rmse_compat(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "# ============================\n",
    "# Registro runtime/memory (MB decimal)\n",
    "# ============================\n",
    "runtime_records = []\n",
    "\n",
    "def add_runtime_record(stage: str, detail: str, time_sec: float, mem_peak_mb: float, mem_start_mb: float, mem_end_mb: float):\n",
    "    runtime_records.append({\n",
    "        \"stage\": stage,\n",
    "        \"detail\": detail,\n",
    "        \"time_seconds\": float(time_sec),\n",
    "        \"memory_peak_MB\": float(mem_peak_mb),\n",
    "        \"memory_start_MB\": float(mem_start_mb),\n",
    "        \"memory_end_MB\": float(mem_end_mb),\n",
    "    })\n",
    "\n",
    "def profile_stage_total_MB(fn, interval: float = 0.05):\n",
    "    \"\"\"\n",
    "    Ejecuta fn() y mide:\n",
    "      - tiempo total\n",
    "      - memoria TOTAL (RSS) en MiB (según memory_profiler), convertida a MB (decimal)\n",
    "      - peak/start/end en MB\n",
    "    \"\"\"\n",
    "    start_t = time.perf_counter()\n",
    "    mem_trace_mib, out = memory_usage((fn, (), {}), retval=True, interval=interval)\n",
    "    end_t = time.perf_counter()\n",
    "\n",
    "    mib_to_mb = 1.048576  # MB decimales\n",
    "    mem_start_mb = float(mem_trace_mib[0] * mib_to_mb)\n",
    "    mem_end_mb   = float(mem_trace_mib[-1] * mib_to_mb)\n",
    "    mem_peak_mb  = float(max(mem_trace_mib) * mib_to_mb)\n",
    "\n",
    "    return out, (end_t - start_t), mem_peak_mb, mem_start_mb, mem_end_mb\n",
    "\n",
    "print(\"OK: imports done.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1) Load dataset, drop highly correlated features, define display names\n",
    "\n",
    "# %%\n",
    "csv_path = BASE_DIR / \"cbc_synthetic_30000_enriched_v2.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"Shape (raw):\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# Targets crudos\n",
    "target_cols = [\"y_hgb_gdl\", \"y_hct_pct\", \"y_rbc_10^12_per_L\"]\n",
    "\n",
    "# Nombres bonitos outputs\n",
    "target_display_map = {\n",
    "    \"y_hgb_gdl\": \"HGB (g/dL)\",\n",
    "    \"y_hct_pct\": \"HCT (%)\",\n",
    "    \"y_rbc_10^12_per_L\": \"RBC (10^12/L)\",\n",
    "}\n",
    "target_display_names = [target_display_map[t] for t in target_cols]\n",
    "\n",
    "# Features crudas\n",
    "feature_cols_raw = [c for c in df.columns if c not in target_cols]\n",
    "\n",
    "# Mapeo crudo -> bonito\n",
    "feature_display_map = {\n",
    "    \"age_years\": \"Age (years)\",\n",
    "    \"sex_male\": \"Sex (male=1)\",\n",
    "    \"bmi\": \"BMI\",\n",
    "    \"iron_ugdl\": \"Iron (µg/dL)\",\n",
    "    \"ferritin_ngml\": \"Ferritin (ng/mL)\",\n",
    "    \"vitamin_d_ngml\": \"Vitamin D (ng/mL)\",\n",
    "    \"folate_ngml\": \"Folate (ng/mL)\",\n",
    "    \"vitamin_b12_pgml\": \"Vitamin B12 (pg/mL)\",\n",
    "    \"crp_mgL\": \"CRP (mg/L)\",\n",
    "    \"albumin_gdl\": \"Albumin (g/dL)\",\n",
    "    \"creatinine_mgdl\": \"Creatinine (mg/dL)\",\n",
    "    \"egfr_ml_min\": \"eGFR (mL/min)\",\n",
    "    \"sbp_mmHg\": \"Systolic BP (mmHg)\",\n",
    "    \"dbp_mmHg\": \"Diastolic BP (mmHg)\",\n",
    "    \"heart_rate_bpm\": \"Heart rate (bpm)\",\n",
    "    \"wbc_10^9_per_L\": \"WBC (10^9/L)\",\n",
    "    \"plt_10^9_per_L\": \"Platelets (10^9/L)\",\n",
    "    \"smoker\": \"Smoker (1 = yes)\",\n",
    "    \"alcohol_units_per_week\": \"Alcohol (units/week)\",\n",
    "    \"physical_activity_level\": \"Physical activity level\",\n",
    "}\n",
    "\n",
    "# Correlación features y eliminación |corr| > 0.80\n",
    "corr_features = df[feature_cols_raw].corr()\n",
    "corr_abs = corr_features.abs()\n",
    "\n",
    "to_drop = set()\n",
    "cols = feature_cols_raw\n",
    "threshold = 0.80\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        if corr_abs.iloc[i, j] > threshold:\n",
    "            to_drop.add(cols[j])  # simple: drop col_j\n",
    "\n",
    "print(\"\\nHighly correlated feature pairs (|corr| > 0.80):\")\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        if corr_abs.iloc[i, j] > threshold:\n",
    "            print(f\"{cols[i]}  <->  {cols[j]} : corr = {corr_features.iloc[i, j]:.3f}\")\n",
    "\n",
    "print(\"\\nFeatures to drop due to high correlation:\", to_drop)\n",
    "\n",
    "feature_cols = [c for c in feature_cols_raw if c not in to_drop]\n",
    "\n",
    "print(\"\\nNumber of features before:\", len(feature_cols_raw))\n",
    "print(\"Number of features after drop:\", len(feature_cols))\n",
    "print(\"Final feature list (kept):\")\n",
    "print(feature_cols)\n",
    "\n",
    "display_feature_names = [feature_display_map.get(c, c) for c in feature_cols]\n",
    "\n",
    "with open(OUT_DIR / \"dropped_features_due_corr.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"threshold\": threshold,\n",
    "        \"dropped_features\": sorted(list(to_drop)),\n",
    "        \"final_features_raw\": feature_cols,\n",
    "        \"final_features_display\": display_feature_names\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"\\nTargets description:\")\n",
    "print(df[target_cols].describe())\n",
    "\n",
    "corr_outputs = df[target_cols].corr()\n",
    "print(\"\\nCorrelation among outputs:\")\n",
    "print(corr_outputs)\n",
    "\n",
    "corr_outputs.to_csv(TAB_DIR / \"corr_outputs_true.csv\", index_label=\"target_raw\")\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(corr_outputs.values, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(target_cols)), target_display_names)\n",
    "plt.yticks(range(len(target_cols)), target_display_names)\n",
    "plt.title(\"Correlation — TRUE outputs (CBC v2)\")\n",
    "plt.tight_layout()\n",
    "save_current_fig(IMG_DIR / \"corr_heatmap_true_outputs_cbc_v2\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2) Train/Val/Test split and scaling\n",
    "\n",
    "# %%\n",
    "X = df[feature_cols].values.astype(np.float32)\n",
    "Y = df[target_cols].values.astype(np.float32)\n",
    "\n",
    "print(\"X shape:\", X.shape, \"Y shape:\", Y.shape)\n",
    "\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(\n",
    "    X_temp, Y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_Y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_val_scaled   = scaler_X.transform(X_val)\n",
    "X_test_scaled  = scaler_X.transform(X_test)\n",
    "\n",
    "Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "Y_val_scaled   = scaler_Y.transform(Y_val)\n",
    "Y_test_scaled  = scaler_Y.transform(Y_test)\n",
    "\n",
    "scaler_info = {\n",
    "    \"feature_cols_raw\": feature_cols,\n",
    "    \"feature_cols_display\": display_feature_names,\n",
    "    \"target_cols_raw\": target_cols,\n",
    "    \"target_cols_display\": target_display_names,\n",
    "    \"X_mean\": scaler_X.mean_.tolist(),\n",
    "    \"X_scale\": scaler_X.scale_.tolist(),\n",
    "    \"Y_mean\": scaler_Y.mean_.tolist(),\n",
    "    \"Y_scale\": scaler_Y.scale_.tolist(),\n",
    "}\n",
    "with open(OUT_DIR / \"scalers_cbc_v2.json\", \"w\") as f:\n",
    "    json.dump(scaler_info, f, indent=2)\n",
    "\n",
    "clinical_feature_names = feature_cols\n",
    "clinical_feature_names_display = display_feature_names\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3) Train multi-output linear model (Ridge)\n",
    "\n",
    "# %%\n",
    "# Ridge multi-output: coef_ shape (n_targets, n_features)\n",
    "# (alpha=0 -> equivalente a OLS, pero Ridge suele ser más estable)\n",
    "multi_model = Ridge(alpha=1.0, random_state=42)\n",
    "\n",
    "def _train_multi_core():\n",
    "    multi_model.fit(X_train_scaled, Y_train_scaled)\n",
    "    return None\n",
    "\n",
    "_, train_time_multi, mem_peak_mb, mem_start_mb, mem_end_mb = profile_stage_total_MB(_train_multi_core, interval=0.05)\n",
    "\n",
    "print(f\"\\n[Multi-output LINEAR Ridge] Training time: {train_time_multi:.3f} s\")\n",
    "print(f\"[Multi-output LINEAR Ridge] Training memory PEAK: {mem_peak_mb:.2f} MB (start={mem_start_mb:.2f}, end={mem_end_mb:.2f})\")\n",
    "\n",
    "add_runtime_record(\n",
    "    stage=\"train_multi\",\n",
    "    detail=\"multi-output-linear-ridge\",\n",
    "    time_sec=train_time_multi,\n",
    "    mem_peak_mb=mem_peak_mb,\n",
    "    mem_start_mb=mem_start_mb,\n",
    "    mem_end_mb=mem_end_mb,\n",
    ")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4) Evaluation of multi-output model\n",
    "\n",
    "# %%\n",
    "def eval_split_multi(split_name, X_scaled, Y_real):\n",
    "    preds_std = multi_model.predict(X_scaled)  # (n_samples, n_outputs) en escala Y_train_scaled\n",
    "    preds_real = scaler_Y.inverse_transform(preds_std)\n",
    "\n",
    "    metrics_rows = []\n",
    "    for k, out_name in enumerate(target_cols):\n",
    "        out_display = target_display_map.get(out_name, out_name)\n",
    "        y_true_k = Y_real[:, k]\n",
    "        y_pred_k = preds_real[:, k]\n",
    "\n",
    "        r2   = r2_score(y_true_k, y_pred_k)\n",
    "        rmse = rmse_compat(y_true_k, y_pred_k)\n",
    "        mae  = mean_absolute_error(y_true_k, y_pred_k)\n",
    "\n",
    "        median_thr = np.median(Y_train[:, k])\n",
    "        y_true_bin = (y_true_k > median_thr).astype(int)\n",
    "        y_pred_bin = (y_pred_k > median_thr).astype(int)\n",
    "        f1 = f1_score(y_true_bin, y_pred_bin)\n",
    "\n",
    "        metrics_rows.append({\n",
    "            \"split\": split_name,\n",
    "            \"target_raw\": out_name,\n",
    "            \"target_display\": out_display,\n",
    "            \"R2\": r2,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"F1_median\": f1,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(metrics_rows), preds_real\n",
    "\n",
    "m_tr, preds_tr   = eval_split_multi(\"train\", X_train_scaled, Y_train)\n",
    "m_val, preds_val = eval_split_multi(\"val\",   X_val_scaled,   Y_val)\n",
    "m_te, preds_te   = eval_split_multi(\"test\",  X_test_scaled,  Y_test)\n",
    "\n",
    "metrics_multi = pd.concat([m_tr, m_val, m_te], ignore_index=True)\n",
    "metrics_multi.to_csv(TAB_DIR / \"metrics_multi_linear_ridge_cbc_v2.csv\", index=False)\n",
    "print(metrics_multi)\n",
    "\n",
    "residuals_test = Y_test - preds_te\n",
    "res_corr = pd.DataFrame(residuals_test, columns=target_cols).corr()\n",
    "print(\"\\nResiduals correlation (test):\")\n",
    "print(res_corr)\n",
    "res_corr.to_csv(TAB_DIR / \"residuals_corr_multi_linear_ridge_cbc_v2_test.csv\", index_label=\"target_raw\")\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(res_corr.values, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(target_cols)), target_display_names)\n",
    "plt.yticks(range(len(target_cols)), target_display_names)\n",
    "plt.title(\"Residuals correlation — MULTI-OUTPUT LINEAR (test, v2)\")\n",
    "plt.tight_layout()\n",
    "save_current_fig(IMG_DIR / \"residuals_corr_multi_linear_ridge_cbc_v2_test\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5) SHAP — background & explained sets\n",
    "\n",
    "# %%\n",
    "bg_size  = min(1000, X_train_scaled.shape[0])\n",
    "exp_size = min(2000, X_test_scaled.shape[0])\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "bg_idx  = rng.choice(X_train_scaled.shape[0], size=bg_size, replace=False)\n",
    "exp_idx = rng.choice(X_test_scaled.shape[0],  size=exp_size, replace=False)\n",
    "\n",
    "X_bg_scaled  = X_train_scaled[bg_idx]\n",
    "X_exp_scaled = X_test_scaled[exp_idx]\n",
    "\n",
    "X_exp_np = X_exp_scaled.copy()\n",
    "X_exp_view = pd.DataFrame(X_exp_np, columns=clinical_feature_names)\n",
    "\n",
    "X_exp_unscaled = pd.DataFrame(\n",
    "    scaler_X.inverse_transform(X_exp_np),\n",
    "    columns=clinical_feature_names\n",
    ")\n",
    "\n",
    "print(\"Background shape:\", X_bg_scaled.shape)\n",
    "print(\"Explained shape:\", X_exp_scaled.shape)\n",
    "print(\"Raw feature names order:\", clinical_feature_names)\n",
    "print(\"Display feature names:\", clinical_feature_names_display)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6) Compute SHAP values for multi-output linear model\n",
    "\n",
    "# %%\n",
    "n_outputs  = len(target_cols)\n",
    "n_features = len(clinical_feature_names)\n",
    "\n",
    "def _compute_shap_multi_core():\n",
    "    # Evita warning de feature_perturbation usando masker\n",
    "    masker = shap.maskers.Independent(X_bg_scaled)\n",
    "    explainer_multi = shap.LinearExplainer(multi_model, masker=masker)\n",
    "    shap_values_raw = explainer_multi.shap_values(X_exp_scaled)\n",
    "    return shap_values_raw\n",
    "\n",
    "shap_values_raw, shap_time_multi, mem_peak_mb, mem_start_mb, mem_end_mb = profile_stage_total_MB(\n",
    "    _compute_shap_multi_core, interval=0.05\n",
    ")\n",
    "\n",
    "print(f\"\\n[SHAP multi-output LINEAR] Time: {shap_time_multi:.3f} s\")\n",
    "print(f\"[SHAP multi-output LINEAR] Memory PEAK: {mem_peak_mb:.2f} MB (start={mem_start_mb:.2f}, end={mem_end_mb:.2f})\")\n",
    "\n",
    "add_runtime_record(\n",
    "    stage=\"shap_multi\",\n",
    "    detail=\"multi-output-linear\",\n",
    "    time_sec=shap_time_multi,\n",
    "    mem_peak_mb=mem_peak_mb,\n",
    "    mem_start_mb=mem_start_mb,\n",
    "    mem_end_mb=mem_end_mb,\n",
    ")\n",
    "\n",
    "# Normalizar a lista por output: shap_values_per_output[k] con shape (n_samples, n_features)\n",
    "shap_values_per_output = []\n",
    "\n",
    "if isinstance(shap_values_raw, (list, tuple)):\n",
    "    # esperable: list length = n_outputs\n",
    "    if len(shap_values_raw) != n_outputs:\n",
    "        raise ValueError(f\"Expected {n_outputs} outputs in SHAP list, got {len(shap_values_raw)}\")\n",
    "    for k in range(n_outputs):\n",
    "        arr = np.array(shap_values_raw[k])\n",
    "        arr = np.squeeze(arr)\n",
    "        if arr.ndim == 1:\n",
    "            arr = arr.reshape(-1, n_features)\n",
    "        if arr.shape[1] != n_features:\n",
    "            raise ValueError(f\"Unexpected SHAP shape {arr.shape} for output {target_cols[k]}\")\n",
    "        shap_values_per_output.append(arr)\n",
    "else:\n",
    "    # a veces shap devuelve array (n_samples, n_features, n_outputs)\n",
    "    arr = np.array(shap_values_raw)\n",
    "    if arr.ndim == 3 and arr.shape[2] == n_outputs:\n",
    "        for k in range(n_outputs):\n",
    "            shap_values_per_output.append(arr[:, :, k])\n",
    "    else:\n",
    "        raise ValueError(f\"Cannot interpret SHAP output shape: {arr.shape}\")\n",
    "\n",
    "print(\"Multi-output SHAP shapes per output:\")\n",
    "for k, out_name in enumerate(target_cols):\n",
    "    print(out_name, shap_values_per_output[k].shape)\n",
    "\n",
    "for i, out_name in enumerate(target_cols):\n",
    "    np.save(OUT_DIR / f\"shap_values_multi_linear_{out_name}_cbc_v2.npy\", shap_values_per_output[i])\n",
    "\n",
    "with open(OUT_DIR / \"shap_multi_meta_linear_cbc_v2.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"mode\": \"multi-output-linear\",\n",
    "        \"method\": \"LinearExplainer\",\n",
    "        \"background_size\": int(X_bg_scaled.shape[0]),\n",
    "        \"explain_size\": int(X_exp_scaled.shape[0]),\n",
    "        \"targets_raw\": target_cols,\n",
    "        \"targets_display\": target_display_names,\n",
    "        \"n_features_used\": int(X_exp_scaled.shape[1]),\n",
    "        \"feature_names_raw\": clinical_feature_names,\n",
    "        \"feature_names_display\": clinical_feature_names_display,\n",
    "        \"model\": \"Ridge(alpha=1.0)\",\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"Saved multi-output LINEAR SHAP arrays (.npy) and metadata (.json) for v2.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7) SHAP multi-output — bar, beeswarm, heatmap, dependence (display names)\n",
    "\n",
    "# %%\n",
    "# mean |SHAP| por salida\n",
    "mean_abs = {}\n",
    "for i, out_name in enumerate(target_cols):\n",
    "    vals = shap_values_per_output[i]  # (n_samples, n_features)\n",
    "    s = pd.Series(np.mean(np.abs(vals), axis=0), index=clinical_feature_names_display, name=out_name)\n",
    "    mean_abs[out_name] = s\n",
    "\n",
    "mean_abs_df = pd.DataFrame(mean_abs)\n",
    "mean_abs_df.to_csv(TAB_DIR / \"mean_abs_shap_multi_linear_cbc_v2.csv\", index_label=\"feature_display\")\n",
    "\n",
    "# Bar + beeswarm (Top-5) por salida\n",
    "for i, out_name in enumerate(target_cols):\n",
    "    out_display = target_display_map.get(out_name, out_name)\n",
    "\n",
    "    s = mean_abs[out_name].sort_values(ascending=False)\n",
    "    #top5 = s.head(5)\n",
    "    top5=s.head(10)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(\"white\")\n",
    "    top5[::-1].plot(kind=\"barh\", color=\"#1f77b4\")\n",
    "    plt.title(f\"Top-5 mean |SHAP| — Multi-output LINEAR — {out_display}\")\n",
    "    plt.xlabel(\"Mean |SHAP value|\")\n",
    "    plt.tight_layout()\n",
    "    save_current_fig(IMG_DIR / f\"shap_bar_multi_linear_{_safe_stem(out_name)}_cbc_v2\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    shap.summary_plot(\n",
    "        shap_values_per_output[i],\n",
    "        features=X_exp_unscaled,\n",
    "        feature_names=clinical_feature_names_display,\n",
    "        max_display=6,\n",
    "        cmap=\"viridis\",\n",
    "        show=False,\n",
    "    )\n",
    "    #plt.title(f\"Beeswarm Top-6 — Multi-output LINEAR — {out_display}\")\n",
    "    plt.title(f\"Linear Multi-output model — {out_display}\")\n",
    "    plt.tight_layout()\n",
    "    save_current_fig(IMG_DIR / f\"shap_beeswarm_multi_linear_{_safe_stem(out_name)}_cbc_v2\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "print(\"Saved Top-6 bar & beeswarm plots (multi-output LINEAR) with display names.\")\n",
    "\n",
    "# Heatmap Top-10 (sumando salidas)\n",
    "combined = pd.DataFrame(\n",
    "    {out_name: mean_abs[out_name].values for out_name in target_cols},\n",
    "    index=clinical_feature_names_display,\n",
    ")\n",
    "overall = combined.abs().sum(axis=1).sort_values(ascending=False)\n",
    "topK_heat = 10\n",
    "top_features = overall.head(topK_heat).index.tolist()\n",
    "\n",
    "heat_data = combined.loc[top_features].T  # (n_outputs, topK)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(heat_data.values, aspect=\"auto\", cmap=\"coolwarm\")\n",
    "plt.colorbar(label=\"Mean |SHAP value|\")\n",
    "plt.xticks(np.arange(len(top_features)), top_features, rotation=45, ha=\"right\")\n",
    "plt.yticks(np.arange(len(target_cols)), target_display_names)\n",
    "plt.title(\"Top-10 features — Mean |SHAP| (multi-output LINEAR, CBC v2)\")\n",
    "plt.tight_layout()\n",
    "save_current_fig(IMG_DIR / \"shap_heatmap_multi_linear_top10_cbc_v2\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved heatmap for Top-10 features (multi-output LINEAR).\")\n",
    "\n",
    "# Dependence plot: top-1 por salida\n",
    "name_to_idx = {disp: j for j, disp in enumerate(clinical_feature_names_display)}\n",
    "top1_idx = {}\n",
    "for out_name in target_cols:\n",
    "    s = mean_abs[out_name].sort_values(ascending=False)\n",
    "    feat_display = s.index[0]\n",
    "    feat_idx = name_to_idx[feat_display]\n",
    "    top1_idx[out_name] = (feat_idx, feat_display)\n",
    "\n",
    "print(\"Top-1 features (multi-output LINEAR):\", {k: v[1] for k, v in top1_idx.items()})\n",
    "\n",
    "for out_name in target_cols:\n",
    "    out_display = target_display_map.get(out_name, out_name)\n",
    "    feat_idx, feat_display = top1_idx[out_name]\n",
    "\n",
    "    plt.figure()\n",
    "    shap.dependence_plot(\n",
    "        ind=feat_idx,\n",
    "        shap_values=shap_values_per_output[target_cols.index(out_name)],\n",
    "        features=X_exp_unscaled,\n",
    "        feature_names=clinical_feature_names_display,\n",
    "        show=False,\n",
    "    )\n",
    "    plt.title(f\"SHAP dependence — Multi-output LINEAR — {out_display} vs {feat_display}\")\n",
    "    plt.tight_layout()\n",
    "    save_current_fig(IMG_DIR / f\"shap_dependence_multi_linear_{_safe_stem(out_name)}_feat{feat_idx}_cbc_v2\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "print(\"Saved dependence plots (multi-output LINEAR) with display names.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8) Single-output linear models (Ridge) — training\n",
    "\n",
    "# %%\n",
    "single_models = {}\n",
    "\n",
    "def train_single_output_model(k, out_name):\n",
    "    print(f\"\\n=== Training single-output LINEAR Ridge model for {out_name} ===\")\n",
    "\n",
    "    model_k = Ridge(alpha=1.0, random_state=42)\n",
    "\n",
    "    def _train_single_core():\n",
    "        model_k.fit(X_train_scaled, Y_train_scaled[:, k])\n",
    "        return None\n",
    "\n",
    "    _, t_sec, mem_peak, mem_start, mem_end = profile_stage_total_MB(_train_single_core, interval=0.05)\n",
    "\n",
    "    print(f\"[Single LINEAR {out_name}] Training time: {t_sec:.3f} s\")\n",
    "    print(f\"[Single LINEAR {out_name}] Training memory PEAK: {mem_peak:.2f} MB (start={mem_start:.2f}, end={mem_end:.2f})\")\n",
    "\n",
    "    add_runtime_record(\n",
    "        stage=\"train_single\",\n",
    "        detail=f\"{out_name}-linear-ridge\",\n",
    "        time_sec=t_sec,\n",
    "        mem_peak_mb=mem_peak,\n",
    "        mem_start_mb=mem_start,\n",
    "        mem_end_mb=mem_end,\n",
    "    )\n",
    "\n",
    "    single_models[out_name] = model_k\n",
    "\n",
    "for k, out_name in enumerate(target_cols):\n",
    "    train_single_output_model(k, out_name)\n",
    "\n",
    "print(\"Done: trained 3 single-output linear models.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9) SHAP for single-output linear models\n",
    "\n",
    "# %%\n",
    "single_shap_values = {}\n",
    "\n",
    "for k, out_name in enumerate(target_cols):\n",
    "    print(f\"\\n=== Computing SHAP for single-output LINEAR: {out_name} ===\")\n",
    "    model_k = single_models[out_name]\n",
    "\n",
    "    def _compute_shap_single_core():\n",
    "        masker = shap.maskers.Independent(X_bg_scaled)\n",
    "        explainer_k = shap.LinearExplainer(model_k, masker=masker)\n",
    "        shap_raw = explainer_k.shap_values(X_exp_scaled)  # (n_samples, n_features)\n",
    "        arr = np.array(shap_raw)\n",
    "        arr = np.squeeze(arr)\n",
    "        if arr.ndim == 1:\n",
    "            arr = arr.reshape(-1, n_features)\n",
    "        return arr\n",
    "\n",
    "    shap_arr, t_sec, mem_peak, mem_start, mem_end = profile_stage_total_MB(_compute_shap_single_core, interval=0.05)\n",
    "\n",
    "    print(f\"[SHAP single LINEAR {out_name}] Time: {t_sec:.3f} s\")\n",
    "    print(f\"[SHAP single LINEAR {out_name}] Memory PEAK: {mem_peak:.2f} MB (start={mem_start:.2f}, end={mem_end:.2f})\")\n",
    "\n",
    "    add_runtime_record(\n",
    "        stage=\"shap_single\",\n",
    "        detail=f\"{out_name}-linear\",\n",
    "        time_sec=t_sec,\n",
    "        mem_peak_mb=mem_peak,\n",
    "        mem_start_mb=mem_start,\n",
    "        mem_end_mb=mem_end,\n",
    "    )\n",
    "\n",
    "    single_shap_values[out_name] = shap_arr\n",
    "    np.save(OUT_DIR / f\"shap_values_single_linear_{_safe_stem(out_name)}_cbc_v2.npy\", shap_arr)\n",
    "\n",
    "with open(OUT_DIR / \"shap_single_meta_linear_cbc_v2.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"mode\": \"single-output-linear-per-target\",\n",
    "        \"method\": \"LinearExplainer\",\n",
    "        \"background_size\": int(X_bg_scaled.shape[0]),\n",
    "        \"explain_size\": int(X_exp_scaled.shape[0]),\n",
    "        \"targets_raw\": target_cols,\n",
    "        \"targets_display\": target_display_names,\n",
    "        \"n_features_used\": int(X_exp_scaled.shape[1]),\n",
    "        \"feature_names_raw\": clinical_feature_names,\n",
    "        \"feature_names_display\": clinical_feature_names_display,\n",
    "        \"model\": \"Ridge(alpha=1.0)\",\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"Saved single-output LINEAR SHAP arrays and metadata.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10) SHAP single-output — mean |SHAP|, bar & beeswarm\n",
    "\n",
    "# %%\n",
    "mean_abs_single = {}\n",
    "for out_name in target_cols:\n",
    "    v = np.abs(single_shap_values[out_name]).mean(axis=0)\n",
    "    s = pd.Series(v, index=clinical_feature_names_display).sort_values(ascending=False)\n",
    "    mean_abs_single[out_name] = s\n",
    "    s.to_csv(\n",
    "        TAB_DIR / f\"mean_abs_shap_single_linear_{_safe_stem(out_name)}_cbc_v2.csv\",\n",
    "        header=[\"mean_abs_shap\"],\n",
    "        index_label=\"feature_display\",\n",
    "    )\n",
    "\n",
    "combined_single = pd.DataFrame(\n",
    "    {out_name: mean_abs_single[out_name].values for out_name in target_cols},\n",
    "    index=clinical_feature_names_display,\n",
    ")\n",
    "combined_single.to_csv(\n",
    "    TAB_DIR / \"mean_abs_shap_single_linear_all_cbc_v2.csv\",\n",
    "    index_label=\"feature_display\",\n",
    ")\n",
    "\n",
    "print(\"Saved mean |SHAP| tables for single-output LINEAR models.\")\n",
    "\n",
    "for out_name in target_cols:\n",
    "    out_display = target_display_map.get(out_name, out_name)\n",
    "    s = mean_abs_single[out_name].sort_values(ascending=False)\n",
    "    #top5 = s.head(5)\n",
    "    top5=s.head(10)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(\"white\")\n",
    "    top5[::-1].plot(kind=\"barh\", color=\"#1f77b4\")\n",
    "    plt.title(f\"Top-5 mean |SHAP| — Single-output LINEAR — {out_display}\")\n",
    "    plt.xlabel(\"Mean |SHAP value|\")\n",
    "    plt.tight_layout()\n",
    "    save_current_fig(IMG_DIR / f\"shap_bar_single_linear_{_safe_stem(out_name)}_cbc_v2\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    shap.summary_plot(\n",
    "        single_shap_values[out_name],\n",
    "        X_exp_view,\n",
    "        feature_names=clinical_feature_names_display,\n",
    "        max_display=6,\n",
    "        show=False,\n",
    "    )\n",
    "    plt.title(f\"SHAP beeswarm — Single-output LINEAR — {out_display}\")\n",
    "    plt.tight_layout()\n",
    "    save_current_fig(IMG_DIR / f\"shap_beeswarm_top5_single_linear_{_safe_stem(out_name)}_cbc_v2\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "print(\"Saved Top-5 bar & beeswarm plots for single-output LINEAR models.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 11) SHAP single-output — heatmap, dependence, cross-output SHAP corr\n",
    "\n",
    "# %%\n",
    "overall_single = combined_single.abs().sum(axis=1).sort_values(ascending=False)\n",
    "topK_single = 10\n",
    "top_features_single = overall_single.head(topK_single).index.tolist()\n",
    "\n",
    "heat_single = combined_single.loc[top_features_single, :].values\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(heat_single, aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(target_display_names)), target_display_names, rotation=0)\n",
    "plt.yticks(range(len(top_features_single)), top_features_single)\n",
    "plt.title(\"Mean |SHAP| (single-output LINEAR, v2) — Top features vs targets\")\n",
    "plt.tight_layout()\n",
    "save_current_fig(IMG_DIR / \"shap_heatmap_single_linear_top_features_cbc_v2\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "top1_single_idx = {}\n",
    "name_to_idx = {disp: j for j, disp in enumerate(clinical_feature_names_display)}\n",
    "for out_name in target_cols:\n",
    "    s = mean_abs_single[out_name]\n",
    "    feat_display = s.index[0]\n",
    "    feat_idx = name_to_idx[feat_display]\n",
    "    top1_single_idx[out_name] = (feat_idx, feat_display)\n",
    "\n",
    "print(\"Top-1 features (single-output LINEAR):\", {k: v[1] for k, v in top1_single_idx.items()})\n",
    "\n",
    "for out_name in target_cols:\n",
    "    out_display = target_display_map.get(out_name, out_name)\n",
    "    feat_idx, feat_display = top1_single_idx[out_name]\n",
    "\n",
    "    plt.figure()\n",
    "    shap.dependence_plot(\n",
    "        ind=feat_idx,\n",
    "        shap_values=single_shap_values[out_name],\n",
    "        features=X_exp_unscaled,\n",
    "        feature_names=clinical_feature_names_display,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(f\"SHAP dependence — Single-output LINEAR — {out_display} vs {feat_display}\")\n",
    "    save_current_fig(IMG_DIR / f\"shap_dependence_single_linear_{_safe_stem(out_name)}_feat{feat_idx}_cbc_v2\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "from itertools import combinations\n",
    "corr_rows_single = []\n",
    "for outA, outB in combinations(target_cols, 2):\n",
    "    svA = single_shap_values[outA]\n",
    "    svB = single_shap_values[outB]\n",
    "\n",
    "    mean_shap_A = pd.Series(svA.mean(axis=0), index=clinical_feature_names_display)\n",
    "    mean_shap_B = pd.Series(svB.mean(axis=0), index=clinical_feature_names_display)\n",
    "    c = mean_shap_A.corr(mean_shap_B)\n",
    "\n",
    "    corr_rows_single.append({\n",
    "        \"output_A_raw\": outA,\n",
    "        \"output_A_display\": target_display_map.get(outA, outA),\n",
    "        \"output_B_raw\": outB,\n",
    "        \"output_B_display\": target_display_map.get(outB, outB),\n",
    "        \"featurewise_SHAP_corr\": float(c)\n",
    "    })\n",
    "\n",
    "corr_df_single = pd.DataFrame(corr_rows_single)\n",
    "corr_df_single.to_csv(TAB_DIR / \"cross_output_shap_single_linear_featurewise_corr_cbc_v2.csv\", index=False)\n",
    "print(corr_df_single)\n",
    "print(\"Saved cross-output SHAP correlation CSV for single-output LINEAR models.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12) Output correlations: TRUE vs multi-output vs single-output (display names)\n",
    "\n",
    "# %%\n",
    "print(\"=== Computing correlations among HGB, HCT, RBC (v2) ===\")\n",
    "\n",
    "true_corr = pd.DataFrame(Y_test, columns=target_cols).corr()\n",
    "\n",
    "preds_multi_std = multi_model.predict(X_test_scaled)\n",
    "preds_multi = scaler_Y.inverse_transform(preds_multi_std)\n",
    "preds_multi_df = pd.DataFrame(preds_multi, columns=target_cols)\n",
    "multi_corr = preds_multi_df.corr()\n",
    "\n",
    "preds_single_dict = {}\n",
    "for k, out_name in enumerate(target_cols):\n",
    "    model_k = single_models[out_name]\n",
    "    pred_scaled = model_k.predict(X_test_scaled).reshape(-1)\n",
    "    pred_real = pred_scaled * scaler_Y.scale_[k] + scaler_Y.mean_[k]\n",
    "    preds_single_dict[out_name] = pred_real\n",
    "\n",
    "preds_single_df = pd.DataFrame(preds_single_dict)\n",
    "single_corr = preds_single_df.corr()\n",
    "\n",
    "true_corr.to_csv(TAB_DIR / \"corr_true_outputs_cbc_v2_test.csv\", index_label=\"target_raw\")\n",
    "multi_corr.to_csv(TAB_DIR / \"corr_multi_output_linear_preds_cbc_v2_test.csv\", index_label=\"target_raw\")\n",
    "single_corr.to_csv(TAB_DIR / \"corr_single_output_linear_preds_cbc_v2_test.csv\", index_label=\"target_raw\")\n",
    "\n",
    "print(\"True correlation:\\n\", true_corr)\n",
    "print(\"\\nMulti-output LINEAR preds correlation:\\n\", multi_corr)\n",
    "print(\"\\nSingle-output LINEAR preds correlation:\\n\", single_corr)\n",
    "\n",
    "def plot_corr_heatmap(mat, title, filename):\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.imshow(mat, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(len(target_display_names)), target_display_names)\n",
    "    plt.yticks(range(len(target_display_names)), target_display_names)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    save_current_fig(IMG_DIR / filename)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_corr_heatmap(true_corr.values,\n",
    "                  \"Correlation — TRUE outputs (test, v2)\",\n",
    "                  \"corr_heatmap_true_outputs_cbc_v2_test\")\n",
    "\n",
    "plot_corr_heatmap(multi_corr.values,\n",
    "                  \"Correlation — MULTI-OUTPUT LINEAR predictions (test, v2)\",\n",
    "                  \"corr_heatmap_multi_output_linear_preds_cbc_v2_test\")\n",
    "\n",
    "plot_corr_heatmap(single_corr.values,\n",
    "                  \"Correlation — SINGLE-OUTPUT LINEAR predictions (test, v2)\",\n",
    "                  \"corr_heatmap_single_output_linear_preds_cbc_v2_test\")\n",
    "\n",
    "print(\"\\n=== Done! Correlation matrices and heatmaps saved successfully (LINEAR v2). ===\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 13) Save runtime & memory summary (MB)\n",
    "\n",
    "# %%\n",
    "runtime_df = pd.DataFrame(runtime_records)\n",
    "csv_path = TAB_DIR / \"runtime_memory_cbc_v2_MB_linear.csv\"\n",
    "runtime_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"\\n=== Runtime & Memory summary saved ===\")\n",
    "print(\"Path:\", csv_path)\n",
    "print(runtime_df)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 14) Evaluation metrics for Multi-output and Single-output Models (Train / Val / Test)\n",
    "\n",
    "# %%\n",
    "def eval_multi_split_all(split_name, X_scaled, Y_real):\n",
    "    preds_scaled = multi_model.predict(X_scaled)\n",
    "    preds_real = scaler_Y.inverse_transform(preds_scaled)\n",
    "\n",
    "    rows = []\n",
    "    for j, out_name in enumerate(target_cols):\n",
    "        out_display = target_display_map.get(out_name, out_name)\n",
    "\n",
    "        y_true = Y_real[:, j]\n",
    "        y_pred = preds_real[:, j]\n",
    "\n",
    "        r2   = r2_score(y_true, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mae  = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "        median_thr = np.median(y_true)\n",
    "        y_true_bin = (y_true > median_thr).astype(int)\n",
    "        y_pred_bin = (y_pred > median_thr).astype(int)\n",
    "        f1 = f1_score(y_true_bin, y_pred_bin)\n",
    "\n",
    "        rows.append({\n",
    "            \"model_type\": \"multi-output-linear\",\n",
    "            \"split\": split_name,\n",
    "            \"output\": out_display,\n",
    "            \"R2\": r2,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"F1_median\": f1,\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "metrics_multi_all = []\n",
    "metrics_multi_all += eval_multi_split_all(\"train\", X_train_scaled, Y_train)\n",
    "metrics_multi_all += eval_multi_split_all(\"val\",   X_val_scaled,   Y_val)\n",
    "metrics_multi_all += eval_multi_split_all(\"test\",  X_test_scaled,  Y_test)\n",
    "\n",
    "df_metrics_multi_all = pd.DataFrame(metrics_multi_all)\n",
    "df_metrics_multi_all.to_csv(TAB_DIR / \"metrics_multi_output_linear_all_splits_cbc_v2.csv\", index=False)\n",
    "\n",
    "print(\"Multi-output LINEAR metrics (train/val/test):\")\n",
    "print(df_metrics_multi_all)\n",
    "\n",
    "\n",
    "def eval_single_split_all(split_name, X_scaled, Y_real):\n",
    "    rows = []\n",
    "    for k, out_name in enumerate(target_cols):\n",
    "        out_display = target_display_map.get(out_name, out_name)\n",
    "\n",
    "        model_k = single_models[out_name]\n",
    "        pred_scaled = model_k.predict(X_scaled).reshape(-1)\n",
    "        pred_real = pred_scaled * scaler_Y.scale_[k] + scaler_Y.mean_[k]\n",
    "\n",
    "        y_true_k = Y_real[:, k]\n",
    "\n",
    "        r2_k   = r2_score(y_true_k, pred_real)\n",
    "        rmse_k = np.sqrt(mean_squared_error(y_true_k, pred_real))\n",
    "        mae_k  = mean_absolute_error(y_true_k, pred_real)\n",
    "\n",
    "        median_thr = np.median(y_true_k)\n",
    "        y_true_bin = (y_true_k > median_thr).astype(int)\n",
    "        y_pred_bin = (pred_real > median_thr).astype(int)\n",
    "        f1_k = f1_score(y_true_bin, y_pred_bin)\n",
    "\n",
    "        rows.append({\n",
    "            \"model_type\": \"single-output-linear\",\n",
    "            \"split\": split_name,\n",
    "            \"output\": out_display,\n",
    "            \"R2\": r2_k,\n",
    "            \"RMSE\": rmse_k,\n",
    "            \"MAE\": mae_k,\n",
    "            \"F1_median\": f1_k,\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "metrics_single_all = []\n",
    "metrics_single_all += eval_single_split_all(\"train\", X_train_scaled, Y_train)\n",
    "metrics_single_all += eval_single_split_all(\"val\",   X_val_scaled,   Y_val)\n",
    "metrics_single_all += eval_single_split_all(\"test\",  X_test_scaled,  Y_test)\n",
    "\n",
    "df_metrics_single_all = pd.DataFrame(metrics_single_all)\n",
    "df_metrics_single_all.to_csv(TAB_DIR / \"metrics_single_output_linear_all_splits_cbc_v2.csv\", index=False)\n",
    "\n",
    "print(\"Single-output LINEAR metrics (train/val/test):\")\n",
    "print(df_metrics_single_all)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 15) Redesigned BAR comparison (Multi vs Single) per output (TopK)\n",
    "\n",
    "# %%\n",
    "# -----------------------------\n",
    "# User-configurable parameters\n",
    "# -----------------------------\n",
    "TOPK = 10\n",
    "COLOR_MULTI  = \"#1f77b4\"\n",
    "COLOR_SINGLE = \"#ff7f0e\"\n",
    "\n",
    "FS_TITLE = 18\n",
    "FS_LABEL = 16\n",
    "FS_TICK  = 16\n",
    "FS_LEG   = 13\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.titlesize\": FS_TITLE,\n",
    "    \"axes.labelsize\": FS_LABEL,\n",
    "    \"xtick.labelsize\": FS_TICK,\n",
    "    \"ytick.labelsize\": FS_TICK,\n",
    "    \"legend.fontsize\": FS_LEG,\n",
    "})\n",
    "\n",
    "def mean_abs_series(shap_array, feature_names_display):\n",
    "    return pd.Series(np.mean(np.abs(shap_array), axis=0), index=feature_names_display)\n",
    "\n",
    "for out_idx, out_name in enumerate(target_cols):\n",
    "    out_disp = target_display_map.get(out_name, out_name)\n",
    "\n",
    "    s_multi  = mean_abs_series(shap_values_per_output[out_idx], clinical_feature_names_display)\n",
    "    s_single = mean_abs_series(single_shap_values[out_name],     clinical_feature_names_display)\n",
    "\n",
    "    s_combined = (s_multi + s_single).sort_values(ascending=False)\n",
    "    top_feats = s_combined.head(TOPK).index.tolist()\n",
    "\n",
    "    df_bar = pd.DataFrame({\n",
    "        \"Multi-output\":  s_multi.loc[top_feats].values,\n",
    "        \"Single-output\": s_single.loc[top_feats].values,\n",
    "    }, index=top_feats)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(\"white\")\n",
    "\n",
    "    y = np.arange(len(top_feats))\n",
    "    h = 0.38\n",
    "\n",
    "    ax.barh(y - h/2, df_bar[\"Multi-output\"],  height=h, color=COLOR_MULTI,  label=\"Multi-output\")\n",
    "    ax.barh(y + h/2, df_bar[\"Single-output\"], height=h, color=COLOR_SINGLE, label=\"Single-output\")\n",
    "\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(top_feats, fontsize=FS_TICK)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_xlabel(\"Mean |SHAP value|\", fontsize=FS_LABEL)\n",
    "    ax.legend(loc=\"lower right\", fontsize=FS_LEG)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_current_fig(IMG_DIR / f\"redesign_bar_compare_multi_vs_single_linear_{out_idx}_top{TOPK}_cbc_v2\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Saved redesigned BAR comparison plots (Top-{TOPK}) for all outputs (LINEAR).\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 16) Quantitative similarity of raw SHAP values (multi vs single)\n",
    "\n",
    "# %%\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def cosine_similarity(vec_a, vec_b, eps=1e-12):\n",
    "    num = np.dot(vec_a, vec_b)\n",
    "    den = (np.linalg.norm(vec_a) * np.linalg.norm(vec_b)) + eps\n",
    "    return float(num / den)\n",
    "\n",
    "similarity_rows = []\n",
    "\n",
    "for k, out_name in enumerate(target_cols):\n",
    "    out_display = target_display_map.get(out_name, out_name)\n",
    "\n",
    "    shap_multi  = shap_values_per_output[k]\n",
    "    shap_single = single_shap_values[out_name]\n",
    "\n",
    "    if shap_multi.shape != shap_single.shape:\n",
    "        raise ValueError(f\"Shape mismatch for output {out_name}: multi {shap_multi.shape}, single {shap_single.shape}\")\n",
    "\n",
    "    vec_multi  = shap_multi.reshape(-1)\n",
    "    vec_single = shap_single.reshape(-1)\n",
    "\n",
    "    cos_sim = cosine_similarity(vec_multi, vec_single)\n",
    "    spearman_corr, spearman_p = spearmanr(vec_multi, vec_single)\n",
    "\n",
    "    similarity_rows.append({\n",
    "        \"output_raw\": out_name,\n",
    "        \"output_display\": out_display,\n",
    "        \"n_samples\": shap_multi.shape[0],\n",
    "        \"n_features\": shap_multi.shape[1],\n",
    "        \"cosine_similarity\": cos_sim,\n",
    "        \"spearman_correlation\": float(spearman_corr),\n",
    "        \"spearman_pvalue\": float(spearman_p),\n",
    "    })\n",
    "\n",
    "similarity_df = pd.DataFrame(similarity_rows)\n",
    "csv_path = TAB_DIR / \"shap_local_similarity_multi_vs_single_linear_cbc_v2.csv\"\n",
    "similarity_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"\\n=== Local SHAP similarity (LINEAR multi vs single) — per output ===\")\n",
    "print(similarity_df)\n",
    "print(f\"\\nSaved SHAP similarity metrics to:\\n{csv_path}\")\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    \"metric\": [\"cosine_similarity\", \"spearman_correlation\"],\n",
    "    \"mean\": [\n",
    "        similarity_df[\"cosine_similarity\"].mean(),\n",
    "        similarity_df[\"spearman_correlation\"].mean(),\n",
    "    ],\n",
    "    \"std\": [\n",
    "        similarity_df[\"cosine_similarity\"].std(ddof=1),\n",
    "        similarity_df[\"spearman_correlation\"].std(ddof=1),\n",
    "    ],\n",
    "})\n",
    "summary_path = TAB_DIR / \"shap_local_similarity_summary_multi_vs_single_linear_cbc_v2.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "\n",
    "print(\"\\n=== Summary across outputs (mean ± std) ===\")\n",
    "print(summary_df)\n",
    "print(f\"\\nSaved summary to:\\n{summary_path}\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 17) Local SHAP similarity restricted to Top-5 features (per output)\n",
    "\n",
    "# %%\n",
    "topK = 10\n",
    "similarity_topk_rows = []\n",
    "\n",
    "for k, out_name in enumerate(target_cols):\n",
    "    out_display = target_display_map.get(out_name, out_name)\n",
    "\n",
    "    shap_multi  = shap_values_per_output[k]\n",
    "    shap_single = single_shap_values[out_name]\n",
    "\n",
    "    mean_multi  = np.mean(np.abs(shap_multi), axis=0)\n",
    "    mean_single = np.mean(np.abs(shap_single), axis=0)\n",
    "\n",
    "    combined_importance = mean_multi + mean_single\n",
    "    topk_idx = np.argsort(combined_importance)[::-1][:topK]\n",
    "    topk_features_display = [clinical_feature_names_display[j] for j in topk_idx]\n",
    "\n",
    "    shap_multi_topk  = shap_multi[:, topk_idx]\n",
    "    shap_single_topk = shap_single[:, topk_idx]\n",
    "\n",
    "    vec_multi  = shap_multi_topk.reshape(-1)\n",
    "    vec_single = shap_single_topk.reshape(-1)\n",
    "\n",
    "    cos_sim = cosine_similarity(vec_multi, vec_single)\n",
    "    spearman_corr, spearman_p = spearmanr(vec_multi, vec_single)\n",
    "\n",
    "    similarity_topk_rows.append({\n",
    "        \"output_raw\": out_name,\n",
    "        \"output_display\": out_display,\n",
    "        \"topK\": topK,\n",
    "        \"topK_features_display\": \"; \".join(topk_features_display),\n",
    "        \"n_samples\": shap_multi_topk.shape[0],\n",
    "        \"cosine_similarity_topK\": cos_sim,\n",
    "        \"spearman_correlation_topK\": float(spearman_corr),\n",
    "        \"spearman_pvalue_topK\": float(spearman_p),\n",
    "    })\n",
    "\n",
    "similarity_topk_df = pd.DataFrame(similarity_topk_rows)\n",
    "csv_path = TAB_DIR / \"shap_local_similarity_top5_multi_vs_single_linear_cbc_v2.csv\"\n",
    "similarity_topk_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"\\n=== Local SHAP similarity (Top-5 features, LINEAR multi vs single) ===\")\n",
    "print(similarity_topk_df)\n",
    "print(f\"\\nSaved Top-5 SHAP similarity metrics to:\\n{csv_path}\")\n",
    "\n",
    "summary_topk_df = pd.DataFrame({\n",
    "    \"metric\": [\"cosine_similarity_topK\", \"spearman_correlation_topK\"],\n",
    "    \"mean\": [\n",
    "        similarity_topk_df[\"cosine_similarity_topK\"].mean(),\n",
    "        similarity_topk_df[\"spearman_correlation_topK\"].mean(),\n",
    "    ],\n",
    "    \"std\": [\n",
    "        similarity_topk_df[\"cosine_similarity_topK\"].std(ddof=1),\n",
    "        similarity_topk_df[\"spearman_correlation_topK\"].std(ddof=1),\n",
    "    ],\n",
    "})\n",
    "summary_path = TAB_DIR / \"shap_local_similarity_top5_summary_multi_vs_single_linear_cbc_v2.csv\"\n",
    "summary_topk_df.to_csv(summary_path, index=False)\n",
    "\n",
    "print(\"\\n=== Top-5 summary across outputs (mean ± std) ===\")\n",
    "print(summary_topk_df)\n",
    "print(f\"\\nSaved Top-5 summary to:\\n{summary_path}\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 18) Combined figure: Top-5 mean |SHAP| (Multi vs Single) for all outputs\n",
    "\n",
    "# %%\n",
    "print(\"\\n[FIG18] Starting combined TopK mean|SHAP| figure...\")\n",
    "\n",
    "TOPK = 10\n",
    "FS_TITLE = 16\n",
    "FS_LABEL = 14\n",
    "FS_TICK  = 12\n",
    "FS_LEG   = 12\n",
    "COLOR_MULTI  = \"#1f77b4\"\n",
    "COLOR_SINGLE = \"#ff7f0e\"\n",
    "\n",
    "def _mean_abs_series(shap_array, feature_names_display):\n",
    "    return pd.Series(np.mean(np.abs(shap_array), axis=0), index=feature_names_display)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(target_cols), figsize=(20, 6), constrained_layout=True)\n",
    "if len(target_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "bar_width = 0.38\n",
    "\n",
    "for out_idx, out_name in enumerate(target_cols):\n",
    "    ax = axes[out_idx]\n",
    "    out_disp = target_display_map.get(out_name, out_name)\n",
    "\n",
    "    s_multi  = _mean_abs_series(shap_values_per_output[out_idx], clinical_feature_names_display)\n",
    "    s_single = _mean_abs_series(single_shap_values[out_name],     clinical_feature_names_display)\n",
    "\n",
    "    s_combined = (s_multi + s_single).sort_values(ascending=False)\n",
    "    top_feats = s_combined.head(TOPK).index.tolist()\n",
    "\n",
    "    y_multi  = s_multi.loc[top_feats].values\n",
    "    y_single = s_single.loc[top_feats].values\n",
    "\n",
    "    x = np.arange(len(top_feats))\n",
    "    ax.bar(x - bar_width/2, y_multi,  width=bar_width, color=COLOR_MULTI,  label=\"Multi-output\")\n",
    "    ax.bar(x + bar_width/2, y_single, width=bar_width, color=COLOR_SINGLE, label=\"Single-output\")\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(top_feats, rotation=90, ha=\"center\", fontsize=FS_TICK)\n",
    "\n",
    "    if out_idx == 0:\n",
    "        ax.set_ylabel(\"Mean |SHAP value|\", fontsize=FS_LABEL)\n",
    "\n",
    "    ax.set_title(out_disp, fontsize=FS_TITLE)\n",
    "    ax.tick_params(axis=\"y\", labelsize=FS_TICK)\n",
    "    ax.grid(axis=\"y\", alpha=0.25)\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"lower center\", ncol=2, fontsize=FS_LEG, frameon=True)\n",
    "\n",
    "plt.subplots_adjust(bottom=0.30)\n",
    "\n",
    "out_path = IMG_DIR / f\"combined_top{TOPK}_bar_mean_abs_shap_multi_vs_single_all_outputs_linear_cbc_v2\"\n",
    "save_current_fig(out_path)\n",
    "\n",
    "print(f\"[FIG18] Saved figure to: {out_path.with_suffix('.png')} and {out_path.with_suffix('.pdf')}\")\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"[FIG18] Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22d929c-dd98-4de1-80cc-099510c5fc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (stroke-mlp2)",
   "language": "python",
   "name": "stroke-mlp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

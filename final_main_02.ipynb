{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137fd523-69f9-4cc5-9be0-a85c82edc1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # CBC Multi-Output (v2) — HGB, HCT, RBC\n",
    "#\n",
    "# - Usa el dataset: cbc_synthetic_30000_enriched_v2.csv\n",
    "# - Elimina features fuertemente correlacionadas (|corr| > 0.80) antes de entrenar\n",
    "# - Entrena modelo multi-output y modelos single-output\n",
    "# - Calcula SHAP para ambos casos\n",
    "# - Usa nombres \"bonitos\" para features y outputs en tablas y gráficos\n",
    "# - Mide tiempo y memoria de entrenamiento y SHAP (multi vs single-output)\n",
    "#   - Memoria medida como TOTAL PEAK en MB (decimal), NO delta.\n",
    "\n",
    "# %%\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import shap\n",
    "from memory_profiler import memory_usage  # para medir memoria (devuelve MiB)\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    f1_score        \n",
    ")\n",
    "\n",
    "# Directorios base (ajusta BASE_DIR si lo necesitas)\n",
    "BASE_DIR = Path(\".\")\n",
    "OUT_DIR  = BASE_DIR / \"cbc_multi_output_v2_outputs_time_memory_MB_05\"\n",
    "IMG_DIR  = OUT_DIR / \"figs\"\n",
    "TAB_DIR  = OUT_DIR / \"tables\"\n",
    "\n",
    "for d in [OUT_DIR, IMG_DIR, TAB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_current_fig(path_no_ext: Path):\n",
    "    path_no_ext = Path(path_no_ext)\n",
    "    plt.savefig(path_no_ext.with_suffix(\".png\"), bbox_inches=\"tight\", dpi=300)\n",
    "    plt.savefig(path_no_ext.with_suffix(\".pdf\"), bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "def rmse_compat(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ============================\n",
    "# NUEVO: Registro global runtime/memory en MB (decimal)\n",
    "# ============================\n",
    "runtime_records = []\n",
    "\n",
    "def add_runtime_record(stage: str, detail: str, time_sec: float, mem_peak_mb: float, mem_start_mb: float, mem_end_mb: float):\n",
    "    \"\"\"\n",
    "    stage: 'train_multi', 'train_single', 'shap_multi', 'shap_single'\n",
    "    detail: por ejemplo 'multi-output' o el nombre del output ('y_hgb_gdl', etc.)\n",
    "    time_sec: tiempo en segundos\n",
    "    mem_peak_mb: memoria TOTAL pico en MB (decimal)\n",
    "    mem_start_mb: memoria al inicio en MB\n",
    "    mem_end_mb: memoria al final en MB\n",
    "    \"\"\"\n",
    "    runtime_records.append({\n",
    "        \"stage\": stage,\n",
    "        \"detail\": detail,\n",
    "        \"time_seconds\": float(time_sec),\n",
    "        \"memory_peak_MB\": float(mem_peak_mb),\n",
    "        \"memory_start_MB\": float(mem_start_mb),\n",
    "        \"memory_end_MB\": float(mem_end_mb),\n",
    "    })\n",
    "\n",
    "def profile_stage_total_MB(fn, interval: float = 0.05):\n",
    "    \"\"\"\n",
    "    Ejecuta fn() y mide:\n",
    "      - tiempo total\n",
    "      - memoria TOTAL (RSS) en MiB (según memory_profiler), convertida a MB (decimal)\n",
    "      - reporta peak/start/end en MB\n",
    "\n",
    "    Nota: memory_usage devuelve MiB. Conversión estricta:\n",
    "      1 MiB = 1.048576 MB\n",
    "    \"\"\"\n",
    "    start_t = time.perf_counter()\n",
    "    mem_trace_mib, out = memory_usage((fn, (), {}), retval=True, interval=interval)\n",
    "    end_t = time.perf_counter()\n",
    "\n",
    "    mib_to_mb = 1.048576  # MB decimales\n",
    "    mem_start_mb = float(mem_trace_mib[0] * mib_to_mb)\n",
    "    mem_end_mb   = float(mem_trace_mib[-1] * mib_to_mb)\n",
    "    mem_peak_mb  = float(max(mem_trace_mib) * mib_to_mb)\n",
    "\n",
    "    return out, (end_t - start_t), mem_peak_mb, mem_start_mb, mem_end_mb\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1) Load dataset, drop highly correlated features, define display names\n",
    "\n",
    "# %%\n",
    "csv_path = BASE_DIR / \"cbc_synthetic_30000_enriched_v2.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"Shape (raw):\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# Targets (outputs) crudos\n",
    "target_cols = [\"y_hgb_gdl\", \"y_hct_pct\", \"y_rbc_10^12_per_L\"]\n",
    "\n",
    "# Nombres bonitos para outputs\n",
    "target_display_map = {\n",
    "    \"y_hgb_gdl\": \"HGB (g/dL)\",\n",
    "    \"y_hct_pct\": \"HCT (%)\",\n",
    "    \"y_rbc_10^12_per_L\": \"RBC (10^12/L)\",\n",
    "}\n",
    "target_display_names = [target_display_map[t] for t in target_cols]\n",
    "\n",
    "# Features crudas\n",
    "feature_cols_raw = [c for c in df.columns if c not in target_cols]\n",
    "\n",
    "# Mapeo crudo -> bonito para features (si alguna no está, se deja igual)\n",
    "feature_display_map = {\n",
    "    \"age_years\": \"Age (years)\",\n",
    "    \"sex_male\": \"Sex (male=1)\",\n",
    "    \"bmi\": \"BMI\",\n",
    "    \"iron_ugdl\": \"Iron (µg/dL)\",\n",
    "    \"ferritin_ngml\": \"Ferritin (ng/mL)\",\n",
    "    \"vitamin_d_ngml\": \"Vitamin D (ng/mL)\",\n",
    "    \"folate_ngml\": \"Folate (ng/mL)\",\n",
    "    \"vitamin_b12_pgml\": \"Vitamin B12 (pg/mL)\",\n",
    "    \"crp_mgL\": \"CRP (mg/L)\",\n",
    "    \"albumin_gdl\": \"Albumin (g/dL)\",\n",
    "    \"creatinine_mgdl\": \"Creatinine (mg/dL)\",\n",
    "    \"egfr_ml_min\": \"eGFR (mL/min)\",\n",
    "    \"sbp_mmHg\": \"Systolic BP (mmHg)\",\n",
    "    \"dbp_mmHg\": \"Diastolic BP (mmHg)\",\n",
    "    \"heart_rate_bpm\": \"Heart rate (bpm)\",\n",
    "    \"wbc_10^9_per_L\": \"WBC (10^9/L)\",\n",
    "    \"plt_10^9_per_L\": \"Platelets (10^9/L)\",\n",
    "    \"smoker\": \"Smoker (1 = yes)\",\n",
    "    \"alcohol_units_per_week\": \"Alcohol (units/week)\",\n",
    "    \"physical_activity_level\": \"Physical activity level\",\n",
    "}\n",
    "\n",
    "# 1) Correlación entre features (crudos) y eliminación de |corr| > 0.80\n",
    "corr_features = df[feature_cols_raw].corr()\n",
    "corr_abs = corr_features.abs()\n",
    "\n",
    "to_drop = set()\n",
    "cols = feature_cols_raw\n",
    "threshold = 0.80\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        if corr_abs.iloc[i, j] > threshold:\n",
    "            col_i = cols[i]\n",
    "            col_j = cols[j]\n",
    "            # Estrategia simple: nos quedamos con col_i y eliminamos col_j\n",
    "            to_drop.add(col_j)\n",
    "\n",
    "print(\"\\nHighly correlated feature pairs (|corr| > 0.80):\")\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        if corr_abs.iloc[i, j] > threshold:\n",
    "            print(f\"{cols[i]}  <->  {cols[j]} : corr = {corr_features.iloc[i, j]:.3f}\")\n",
    "\n",
    "print(\"\\nFeatures to drop due to high correlation:\", to_drop)\n",
    "\n",
    "# Features finales tras eliminar las muy correlacionadas\n",
    "feature_cols = [c for c in feature_cols_raw if c not in to_drop]\n",
    "\n",
    "print(\"\\nNumber of features before:\", len(feature_cols_raw))\n",
    "print(\"Number of features after drop:\", len(feature_cols))\n",
    "print(\"Final feature list (kept):\")\n",
    "print(feature_cols)\n",
    "\n",
    "# Nombres bonitos en el orden de feature_cols\n",
    "display_feature_names = [feature_display_map.get(c, c) for c in feature_cols]\n",
    "\n",
    "# Guardar info de features y nombres display\n",
    "with open(OUT_DIR / \"dropped_features_due_corr.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"threshold\": threshold,\n",
    "        \"dropped_features\": sorted(list(to_drop)),\n",
    "        \"final_features_raw\": feature_cols,\n",
    "        \"final_features_display\": display_feature_names\n",
    "    }, f, indent=2)\n",
    "\n",
    "# Descripción básica de salidas\n",
    "print(\"\\nTargets description:\")\n",
    "print(df[target_cols].describe())\n",
    "\n",
    "# Correlación entre outputs\n",
    "corr_outputs = df[target_cols].corr()\n",
    "print(\"\\nCorrelation among outputs:\")\n",
    "print(corr_outputs)\n",
    "\n",
    "corr_outputs.to_csv(TAB_DIR / \"corr_outputs_true.csv\", index_label=\"target_raw\")\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(corr_outputs.values, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(target_cols)), target_display_names)\n",
    "plt.yticks(range(len(target_cols)), target_display_names)\n",
    "plt.title(\"Correlation — TRUE outputs (CBC v2)\")\n",
    "plt.tight_layout()\n",
    "save_current_fig(IMG_DIR / \"corr_heatmap_true_outputs_cbc_v2\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2) Train/Val/Test split and scaling\n",
    "\n",
    "# %%\n",
    "X = df[feature_cols].values.astype(np.float32)\n",
    "Y = df[target_cols].values.astype(np.float32)\n",
    "\n",
    "print(\"X shape:\", X.shape, \"Y shape:\", Y.shape)\n",
    "\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(\n",
    "    X_temp, Y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_Y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_val_scaled   = scaler_X.transform(X_val)\n",
    "X_test_scaled  = scaler_X.transform(X_test)\n",
    "\n",
    "Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "Y_val_scaled   = scaler_Y.transform(Y_val)\n",
    "Y_test_scaled  = scaler_Y.transform(Y_test)\n",
    "\n",
    "scaler_info = {\n",
    "    \"feature_cols_raw\": feature_cols,\n",
    "    \"feature_cols_display\": display_feature_names,\n",
    "    \"target_cols_raw\": target_cols,\n",
    "    \"target_cols_display\": target_display_names,\n",
    "    \"X_mean\": scaler_X.mean_.tolist(),\n",
    "    \"X_scale\": scaler_X.scale_.tolist(),\n",
    "    \"Y_mean\": scaler_Y.mean_.tolist(),\n",
    "    \"Y_scale\": scaler_Y.scale_.tolist(),\n",
    "}\n",
    "with open(OUT_DIR / \"scalers_cbc_v2.json\", \"w\") as f:\n",
    "    json.dump(scaler_info, f, indent=2)\n",
    "\n",
    "# Para SHAP trabajamos con nombres crudos (orden) + nombres display para labels\n",
    "clinical_feature_names = feature_cols          # crudos\n",
    "clinical_feature_names_display = display_feature_names  # bonitos\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3) Multi-output MLP definition\n",
    "\n",
    "# %%\n",
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden=(128, 64), dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last_dim = in_dim\n",
    "        for h in hidden:\n",
    "            layers.append(nn.Linear(last_dim, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout > 0:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            last_dim = h\n",
    "        layers.append(nn.Linear(last_dim, out_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def batches(X_t, Y_t, batch_size=256):\n",
    "    n = X_t.shape[0]\n",
    "    idx = torch.randperm(n, device=X_t.device)\n",
    "    for i in range(0, n, batch_size):\n",
    "        j = idx[i:i+batch_size]\n",
    "        yield X_t[j], Y_t[j]\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4) Train multi-output model\n",
    "\n",
    "# %%\n",
    "in_dim  = X_train_scaled.shape[1]\n",
    "out_dim = Y_train_scaled.shape[1]\n",
    "\n",
    "multi_model = MLPRegressor(in_dim, out_dim, hidden=(128, 64), dropout=0.1).to(device)\n",
    "criterion  = nn.MSELoss()\n",
    "optimizer  = optim.Adam(multi_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "Xtr_t = torch.tensor(X_train_scaled, dtype=torch.float32, device=device)\n",
    "Ytr_t = torch.tensor(Y_train_scaled, dtype=torch.float32, device=device)\n",
    "Xva_t = torch.tensor(X_val_scaled,   dtype=torch.float32, device=device)\n",
    "Yva_t = torch.tensor(Y_val_scaled,   dtype=torch.float32, device=device)\n",
    "\n",
    "max_epochs = 200\n",
    "patience   = 20\n",
    "\n",
    "def _train_multi_core():\n",
    "    \"\"\"\n",
    "    Núcleo de entrenamiento del modelo multi-output.\n",
    "    Devuelve el historial de pérdidas.\n",
    "    \"\"\"\n",
    "    history = {\"train_loss\": [], \"val_loss\": []}\n",
    "    best_val = float(\"inf\")\n",
    "    pat_counter = 0\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        multi_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        preds_tr = multi_model(Xtr_t)\n",
    "        loss_tr = criterion(preds_tr, Ytr_t)\n",
    "        loss_tr.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        multi_model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds_va = multi_model(Xva_t)\n",
    "            loss_va = criterion(preds_va, Yva_t).item()\n",
    "            loss_tr_val = loss_tr.item()\n",
    "\n",
    "        history[\"train_loss\"].append(loss_tr_val)\n",
    "        history[\"val_loss\"].append(loss_va)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:03d}/{max_epochs} | \"\n",
    "            f\"train_loss={loss_tr_val:.6f}, val_loss={loss_va:.6f}\"\n",
    "        )\n",
    "\n",
    "        if loss_va < best_val - 1e-8:\n",
    "            best_val = loss_va\n",
    "            pat_counter = 0\n",
    "            torch.save(multi_model.state_dict(), OUT_DIR / \"best_multi_model_cbc_v2.pt\")\n",
    "        else:\n",
    "            pat_counter += 1\n",
    "            if pat_counter >= patience:\n",
    "                print(\"Early stopping at epoch\", epoch + 1)\n",
    "                break\n",
    "\n",
    "    # Cargamos siempre el mejor modelo guardado\n",
    "    if (OUT_DIR / \"best_multi_model_cbc_v2.pt\").exists():\n",
    "        multi_model.load_state_dict(\n",
    "            torch.load(OUT_DIR / \"best_multi_model_cbc_v2.pt\", map_location=device)\n",
    "        )\n",
    "\n",
    "    return history\n",
    "\n",
    "# --- MEDICIÓN DE TIEMPO Y MEMORIA TOTAL (PEAK) EN MB ---\n",
    "history, train_time_multi, mem_peak_mb, mem_start_mb, mem_end_mb = profile_stage_total_MB(_train_multi_core, interval=0.05)\n",
    "\n",
    "print(f\"\\n[Multi-output] Training time: {train_time_multi:.3f} s\")\n",
    "print(f\"[Multi-output] Training memory PEAK: {mem_peak_mb:.2f} MB (start={mem_start_mb:.2f}, end={mem_end_mb:.2f})\")\n",
    "\n",
    "add_runtime_record(\n",
    "    stage=\"train_multi\",\n",
    "    detail=\"multi-output\",\n",
    "    time_sec=train_time_multi,\n",
    "    mem_peak_mb=mem_peak_mb,\n",
    "    mem_start_mb=mem_start_mb,\n",
    "    mem_end_mb=mem_end_mb,\n",
    ")\n",
    "\n",
    "# Guardamos historial de entrenamiento\n",
    "pd.DataFrame(history).to_csv(TAB_DIR / \"training_history_multi_cbc_v2.csv\", index=False)\n",
    "\n",
    "# --- PLOT: Training vs Validation (colores fijos) ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor(\"#f5f5f5\")\n",
    "plt.plot(history[\"train_loss\"], label=\"Training\",  color=\"#1f77b4\")  # azul\n",
    "plt.plot(history[\"val_loss\"],   label=\"Validation\", color=\"#ff7f0e\")  # naranjo\n",
    "plt.legend(fontsize=14)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlim([0, len(history[\"train_loss\"])])\n",
    "plt.tight_layout()\n",
    "save_current_fig(IMG_DIR / \"training_curve_multi_cbc_v2\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5) Evaluation of multi-output model\n",
    "\n",
    "# %%\n",
    "multi_model.eval()\n",
    "\n",
    "def eval_split_multi(split_name, X_scaled, Y_true, Y_df):\n",
    "    with torch.no_grad():\n",
    "        preds_std = multi_model(\n",
    "            torch.tensor(X_scaled, dtype=torch.float32, device=device)\n",
    "        ).cpu().numpy()\n",
    "\n",
    "    preds = preds_std * scaler_Y.scale_ + scaler_Y.mean_\n",
    "\n",
    "    metrics_rows = []\n",
    "    for k, out_name in enumerate(target_cols):\n",
    "        y_true_k = Y_df[out_name].values\n",
    "        y_pred_k = preds[:, k]\n",
    "\n",
    "        r2   = r2_score(y_true_k, y_pred_k)\n",
    "        rmse = rmse_compat(y_true_k, y_pred_k)\n",
    "        mae  = mean_absolute_error(y_true_k, y_pred_k)\n",
    "\n",
    "        median_thr = np.median(Y_train[:, k])\n",
    "        y_true_bin = (y_true_k > median_thr).astype(int)\n",
    "        y_pred_bin = (y_pred_k > median_thr).astype(int)\n",
    "        f1 = f1_score(y_true_bin, y_pred_bin)\n",
    "\n",
    "        metrics_rows.append({\n",
    "            \"split\": split_name,\n",
    "            \"target_raw\": out_name,\n",
    "            \"target_display\": target_display_map.get(out_name, out_name),\n",
    "            \"R2\": r2,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"F1_median\": f1,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(metrics_rows), preds\n",
    "\n",
    "Y_train_df = pd.DataFrame(Y_train, columns=target_cols)\n",
    "Y_val_df   = pd.DataFrame(Y_val,   columns=target_cols)\n",
    "Y_test_df  = pd.DataFrame(Y_test,  columns=target_cols)\n",
    "\n",
    "m_tr, preds_tr   = eval_split_multi(\"train\", X_train_scaled, Y_train, Y_train_df)\n",
    "m_val, preds_val = eval_split_multi(\"val\",   X_val_scaled,   Y_val,   Y_val_df)\n",
    "m_te, preds_te   = eval_split_multi(\"test\",  X_test_scaled,  Y_test,  Y_test_df)\n",
    "\n",
    "metrics_multi = pd.concat([m_tr, m_val, m_te], ignore_index=True)\n",
    "metrics_multi.to_csv(TAB_DIR / \"metrics_multi_cbc_v2.csv\", index=False)\n",
    "print(metrics_multi)\n",
    "\n",
    "residuals_test = Y_test - preds_te\n",
    "res_corr = pd.DataFrame(residuals_test, columns=target_cols).corr()\n",
    "print(\"\\nResiduals correlation (test):\")\n",
    "print(res_corr)\n",
    "res_corr.to_csv(TAB_DIR / \"residuals_corr_multi_cbc_v2_test.csv\", index_label=\"target_raw\")\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(res_corr.values, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(target_cols)), target_display_names)\n",
    "plt.yticks(range(len(target_cols)), target_display_names)\n",
    "plt.title(\"Residuals correlation — MULTI-OUTPUT (test, v2)\")\n",
    "plt.tight_layout()\n",
    "save_current_fig(IMG_DIR / \"residuals_corr_multi_cbc_v2_test\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6) SHAP — background & explained sets\n",
    "\n",
    "# %%\n",
    "bg_size  = min(1000, X_train_scaled.shape[0])\n",
    "exp_size = min(2000, X_test_scaled.shape[0])\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "bg_idx  = rng.choice(X_train_scaled.shape[0], size=bg_size, replace=False)\n",
    "exp_idx = rng.choice(X_test_scaled.shape[0],  size=exp_size, replace=False)\n",
    "\n",
    "X_bg_scaled = X_train_scaled[bg_idx]\n",
    "X_exp_scaled = X_test_scaled[exp_idx]\n",
    "\n",
    "X_exp_np = X_exp_scaled.copy()\n",
    "# DataFrame con columnas crudas (orden correcto para SHAP)\n",
    "X_exp_view = pd.DataFrame(X_exp_np, columns=clinical_feature_names)\n",
    "\n",
    "X_bg_scaled_t  = torch.tensor(X_bg_scaled,  dtype=torch.float32, device=device)\n",
    "X_exp_scaled_t = torch.tensor(X_exp_scaled, dtype=torch.float32, device=device)\n",
    "\n",
    "X_exp_unscaled = pd.DataFrame(\n",
    "    scaler_X.inverse_transform(X_exp_np),\n",
    "    columns=clinical_feature_names\n",
    ")\n",
    "\n",
    "print(\"Background shape:\", X_bg_scaled.shape)\n",
    "print(\"Explained shape:\", X_exp_scaled.shape)\n",
    "print(\"Raw feature names order:\", clinical_feature_names)\n",
    "print(\"Display feature names:\", clinical_feature_names_display)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7) Compute SHAP values for multi-output model (real feature display names)\n",
    "\n",
    "# %%\n",
    "multi_model.eval()\n",
    "\n",
    "n_outputs  = len(target_cols)\n",
    "n_features = len(clinical_feature_names)\n",
    "\n",
    "def _compute_shap_multi_core():\n",
    "    \"\"\"\n",
    "    Núcleo de cálculo SHAP para el modelo multi-output.\n",
    "    Devuelve la lista/array de valores SHAP sin normalizar.\n",
    "    \"\"\"\n",
    "    explainer_multi = shap.DeepExplainer(multi_model, X_bg_scaled_t)\n",
    "    shap_values_raw = explainer_multi.shap_values(X_exp_scaled_t)\n",
    "    return shap_values_raw\n",
    "\n",
    "# --- MEDICIÓN DE TIEMPO Y MEMORIA TOTAL (PEAK) EN MB PARA SHAP multi ---\n",
    "shap_values_raw, shap_time_multi, mem_peak_mb, mem_start_mb, mem_end_mb = profile_stage_total_MB(_compute_shap_multi_core, interval=0.05)\n",
    "\n",
    "print(f\"\\n[SHAP multi-output] Time: {shap_time_multi:.3f} s\")\n",
    "print(f\"[SHAP multi-output] Memory PEAK: {mem_peak_mb:.2f} MB (start={mem_start_mb:.2f}, end={mem_end_mb:.2f})\")\n",
    "\n",
    "add_runtime_record(\n",
    "    stage=\"shap_multi\",\n",
    "    detail=\"multi-output\",\n",
    "    time_sec=shap_time_multi,\n",
    "    mem_peak_mb=mem_peak_mb,\n",
    "    mem_start_mb=mem_start_mb,\n",
    "    mem_end_mb=mem_end_mb,\n",
    ")\n",
    "\n",
    "# Normalización y reestructuración de los SHAP values como antes\n",
    "shap_values_per_output = []\n",
    "\n",
    "if isinstance(shap_values_raw, (list, tuple)):\n",
    "    if len(shap_values_raw) != n_outputs:\n",
    "        raise ValueError(f\"Expected {n_outputs} outputs in SHAP list, got {len(shap_values_raw)}\")\n",
    "\n",
    "    for k in range(n_outputs):\n",
    "        arr = np.array(shap_values_raw[k])\n",
    "        arr = np.squeeze(arr)\n",
    "        if arr.ndim == 1:\n",
    "            arr = arr.reshape(-1, n_features)\n",
    "        if arr.shape[1] != n_features:\n",
    "            raise ValueError(\n",
    "                f\"Unexpected SHAP shape {arr.shape} for output {target_cols[k]} \"\n",
    "                f\"(expected second dim = {n_features})\"\n",
    "            )\n",
    "        shap_values_per_output.append(arr)\n",
    "else:\n",
    "    arr = np.array(shap_values_raw)\n",
    "    if arr.ndim != 3:\n",
    "        raise ValueError(f\"Unexpected SHAP array ndim={arr.ndim}, expected 3.\")\n",
    "    # Posibles convenciones: (n_samples, n_features, n_outputs) o (n_outputs, n_samples, n_features)\n",
    "    if arr.shape[0] == n_outputs and arr.shape[2] == n_features:\n",
    "        # (n_outputs, n_samples, n_features)\n",
    "        for k in range(n_outputs):\n",
    "            shap_values_per_output.append(arr[k])\n",
    "    elif arr.shape[2] == n_outputs and arr.shape[1] == n_features:\n",
    "        # (n_samples, n_features, n_outputs)\n",
    "        for k in range(n_outputs):\n",
    "            shap_values_per_output.append(arr[:, :, k])\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Cannot interpret SHAP array shape {arr.shape} \"\n",
    "            f\"for n_outputs={n_outputs}, n_features={n_features}\"\n",
    "        )\n",
    "\n",
    "print(\"Multi-output SHAP shapes per output:\")\n",
    "for k, out_name in enumerate(target_cols):\n",
    "    print(out_name, shap_values_per_output[k].shape)\n",
    "\n",
    "# Guardar en .npy por salida\n",
    "for i, out_name in enumerate(target_cols):\n",
    "    np.save(OUT_DIR / f\"shap_values_multi_{out_name}_cbc_v2.npy\", shap_values_per_output[i])\n",
    "\n",
    "with open(OUT_DIR / \"shap_multi_meta_cbc_v2.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"mode\": \"multi-output\",\n",
    "        \"method\": \"DeepExplainer\",\n",
    "        \"background_size\": int(X_bg_scaled.shape[0]),\n",
    "        \"explain_size\": int(X_exp_scaled.shape[0]),\n",
    "        \"targets_raw\": target_cols,\n",
    "        \"targets_display\": target_display_names,\n",
    "        \"n_features_used\": int(X_exp_np.shape[1]),\n",
    "        \"feature_names_raw\": clinical_feature_names,\n",
    "        \"feature_names_display\": clinical_feature_names_display,\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"Saved multi-output SHAP arrays (.npy) and metadata (.json) for v2.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8) SHAP multi-output — bar, beeswarm, heatmap, dependence (display names)\n",
    "\n",
    "# %%\n",
    "n_outputs = len(target_cols)\n",
    "n_features = len(clinical_feature_names_display)\n",
    "\n",
    "# 1) Calcular importancia media absoluta por feature y por salida\n",
    "mean_abs = {}\n",
    "for i, out_name in enumerate(target_cols):\n",
    "    vals = shap_values_per_output[i]  # shape: (n_samples, n_features)\n",
    "    s = pd.Series(\n",
    "        np.mean(np.abs(vals), axis=0),\n",
    "        index=clinical_feature_names_display,\n",
    "        name=out_name,\n",
    "    )\n",
    "    mean_abs[out_name] = s\n",
    "\n",
    "# Guardamos una tabla con las medias absolutas (todas las salidas)\n",
    "mean_abs_df = pd.DataFrame(mean_abs)\n",
    "mean_abs_df.to_csv(\n",
    "    TAB_DIR / \"mean_abs_shap_multi_cbc_v2.csv\",\n",
    "    index_label=\"feature_display\",\n",
    ")\n",
    "\n",
    "# 2) Bar & beeswarm (Top-5) por salida\n",
    "for i, out_name in enumerate(target_cols):\n",
    "    out_display = target_display_map.get(out_name, out_name)\n",
    "\n",
    "    s = mean_abs[out_name].sort_values(ascending=False)\n",
    "    #top5 = s.head(5)\n",
    "    top5=s.head(10)\n",
    "    # --- BAR ---\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(\"white\")\n",
    "    top5[::-1].plot(kind=\"barh\", color=\"#1f77b4\")\n",
    "    plt.title(f\"Top-5 mean |SHAP| — Multi-output — {out_display}\")\n",
    "    plt.xlabel(\"Mean |SHAP value|\")\n",
    "    plt.tight_layout()\n",
    "    save_current_fig(IMG_DIR / f\"shap_bar_multi_{out_name}_cbc_v2\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- BEESWARM ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    shap.summary_plot(\n",
    "        shap_values_per_output[i],\n",
    "        features=X_exp_unscaled,\n",
    "        feature_names=clinical_feature_names_display,\n",
    "        max_display=6,\n",
    "        show=False,\n",
    "    )\n",
    "    #plt.title(f\"Beeswarm Top-5 — Multi-output — {out_display}\")\n",
    "    plt.title(f\"Nonlinear Multi-output model — {out_display}\")\n",
    "    plt.tight_layout()\n",
    "    save_current_fig(IMG_DIR / f\"shap_beeswarm_multi_{out_name}_cbc_v2\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"Saved Top-5 bar & beeswarm plots (multi-output, v2) with display names.\")\n",
    "\n",
    "# 3) Heatmap: Top-10 features por importancia total (sumando salidas)\n",
    "combined = pd.DataFrame(\n",
    "    {out_name: mean_abs[out_name].values for out_name in target_cols},\n",
    "    index=clinical_feature_names_display,\n",
    ")\n",
    "\n",
    "overall = combined.abs().sum(axis=1).sort_values(ascending=False)\n",
    "topK = 10\n",
    "top_features = overall.head(topK).index.tolist()\n",
    "\n",
    "heat_data = combined.loc[top_features].T  # shape: (n_outputs, topK)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(heat_data.values, aspect=\"auto\", cmap=\"coolwarm\")\n",
    "plt.colorbar(label=\"Mean |SHAP value|\")\n",
    "plt.xticks(\n",
    "    ticks=np.arange(len(top_features)),\n",
    "    labels=top_features,\n",
    "    rotation=45,\n",
    "    ha=\"right\",\n",
    ")\n",
    "plt.yticks(\n",
    "    ticks=np.arange(len(target_cols)),\n",
    "    labels=target_display_names,\n",
    ")\n",
    "plt.title(\"Top-10 features — Mean |SHAP| (multi-output, CBC v2)\")\n",
    "plt.tight_layout()\n",
    "save_current_fig(IMG_DIR / \"shap_heatmap_multi_top10_cbc_v2\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved heatmap for Top-10 features (multi-output, v2).\")\n",
    "\n",
    "# 4) Dependence plots: feature Top-1 por salida\n",
    "top1_idx = {}\n",
    "for out_name in target_cols:\n",
    "    s = mean_abs[out_name].sort_values(ascending=False)\n",
    "    feat_display = s.index[0]\n",
    "\n",
    "    name_to_idx = {disp: j for j, disp in enumerate(clinical_feature_names_display)}\n",
    "    feat_idx = name_to_idx[feat_display]\n",
    "    top1_idx[out_name] = (feat_idx, feat_display)\n",
    "\n",
    "print(\"Top-1 features (multi-output, v2):\", {k: v[1] for k, v in top1_idx.items()})\n",
    "\n",
    "for out_name in target_cols:\n",
    "    out_display = target_display_map.get(out_name, out_name)\n",
    "    feat_idx, feat_display = top1_idx[out_name]\n",
    "\n",
    "    plt.figure()\n",
    "    shap.dependence_plot(\n",
    "        ind=feat_idx,\n",
    "        shap_values=shap_values_per_output[target_cols.index(out_name)],\n",
    "        features=X_exp_unscaled,\n",
    "        feature_names=clinical_feature_names_display,\n",
    "        show=False,\n",
    "    )\n",
    "    plt.title(f\"SHAP dependence — Multi-output — {out_display} vs {feat_display}\")\n",
    "    plt.tight_layout()\n",
    "    save_current_fig(IMG_DIR / f\"shap_dependence_multi_{out_name}_feat{feat_idx}_cbc_v2\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"Saved dependence plots (multi-output, v2) with display names.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9) Single-output models (training & evaluation)\n",
    "\n",
    "# %%\n",
    "single_models = {}\n",
    "single_histories = {}\n",
    "\n",
    "def train_single_output_model(k, out_name):\n",
    "    \"\"\"\n",
    "    Entrena un modelo single-output para el índice k y nombre out_name.\n",
    "    Además mide tiempo y memoria TOTAL (pico) en MB.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Training single-output model for {out_name} ===\")\n",
    "\n",
    "    in_dim = X_train_scaled.shape[1]\n",
    "    model_k = MLPRegressor(in_dim, 1, hidden=(128, 64), dropout=0.1).to(device)\n",
    "\n",
    "    criterion_k = nn.MSELoss()\n",
    "    optimizer_k = optim.Adam(model_k.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "    ytr_k = Y_train_scaled[:, k]\n",
    "    yva_k = Y_val_scaled[:, k]\n",
    "\n",
    "    Ytr_k_t = torch.tensor(ytr_k.reshape(-1, 1), dtype=torch.float32, device=device)\n",
    "    Yva_k_t = torch.tensor(yva_k.reshape(-1, 1), dtype=torch.float32, device=device)\n",
    "\n",
    "    Xtr_t_loc = torch.tensor(X_train_scaled, dtype=torch.float32, device=device)\n",
    "    Xva_t_loc = torch.tensor(X_val_scaled,   dtype=torch.float32, device=device)\n",
    "\n",
    "    max_epochs_k = 200\n",
    "    patience_k   = 20\n",
    "\n",
    "    def _train_single_core():\n",
    "        history_k = {\"train_loss\": [], \"val_loss\": []}\n",
    "        best_val = float(\"inf\")\n",
    "        pat_counter = 0\n",
    "\n",
    "        for epoch in range(max_epochs_k):\n",
    "            model_k.train()\n",
    "            optimizer_k.zero_grad()\n",
    "            preds_tr_k = model_k(Xtr_t_loc)\n",
    "            loss_tr_k = criterion_k(preds_tr_k, Ytr_k_t)\n",
    "            loss_tr_k.backward()\n",
    "            optimizer_k.step()\n",
    "\n",
    "            model_k.eval()\n",
    "            with torch.no_grad():\n",
    "                preds_va_k = model_k(Xva_t_loc)\n",
    "                loss_va_k = criterion_k(preds_va_k, Yva_k_t).item()\n",
    "                loss_tr_k_val = loss_tr_k.item()\n",
    "\n",
    "            history_k[\"train_loss\"].append(loss_tr_k_val)\n",
    "            history_k[\"val_loss\"].append(loss_va_k)\n",
    "\n",
    "            print(\n",
    "                f\"[{out_name}] Epoch {epoch+1:03d}/{max_epochs_k} | \"\n",
    "                f\"train_loss={loss_tr_k_val:.6f}, val_loss={loss_va_k:.6f}\"\n",
    "            )\n",
    "\n",
    "            if loss_va_k < best_val - 1e-8:\n",
    "                best_val = loss_va_k\n",
    "                pat_counter = 0\n",
    "                torch.save(model_k.state_dict(), OUT_DIR / f\"best_single_model_{out_name}_cbc_v2.pt\")\n",
    "            else:\n",
    "                pat_counter += 1\n",
    "                if pat_counter >= patience_k:\n",
    "                    print(f\"Early stopping (single {out_name}) at epoch\", epoch + 1)\n",
    "                    break\n",
    "\n",
    "        # Cargar mejor modelo\n",
    "        if (OUT_DIR / f\"best_single_model_{out_name}_cbc_v2.pt\").exists():\n",
    "            model_k.load_state_dict(\n",
    "                torch.load(OUT_DIR / f\"best_single_model_{out_name}_cbc_v2.pt\", map_location=device)\n",
    "            )\n",
    "\n",
    "        return history_k\n",
    "\n",
    "    # --- MEDICIÓN DE TIEMPO Y MEMORIA TOTAL (PEAK) EN MB ---\n",
    "    history_k, train_time_single, mem_peak_mb, mem_start_mb, mem_end_mb = profile_stage_total_MB(_train_single_core, interval=0.05)\n",
    "\n",
    "    print(f\"[Single {out_name}] Training time: {train_time_single:.3f} s\")\n",
    "    print(f\"[Single {out_name}] Training memory PEAK: {mem_peak_mb:.2f} MB (start={mem_start_mb:.2f}, end={mem_end_mb:.2f})\")\n",
    "\n",
    "    add_runtime_record(\n",
    "        stage=\"train_single\",\n",
    "        detail=out_name,\n",
    "        time_sec=train_time_single,\n",
    "        mem_peak_mb=mem_peak_mb,\n",
    "        mem_start_mb=mem_start_mb,\n",
    "        mem_end_mb=mem_end_mb,\n",
    "    )\n",
    "\n",
    "    single_models[out_name] = model_k\n",
    "    single_histories[out_name] = history_k\n",
    "\n",
    "    # Guardar historial y curva\n",
    "    hist_df = pd.DataFrame(history_k)\n",
    "    hist_df.to_csv(TAB_DIR / f\"training_history_single_{out_name}_cbc_v2.csv\", index=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(\"#f5f5f5\")\n",
    "    plt.plot(history_k[\"train_loss\"], label=\"Training\",  color=\"#1f77b4\")\n",
    "    plt.plot(history_k[\"val_loss\"],   label=\"Validation\", color=\"#ff7f0e\")\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlim([0, len(history_k[\"train_loss\"])])\n",
    "    plt.tight_layout()\n",
    "    save_current_fig(IMG_DIR / f\"training_curve_single_{out_name}_cbc_v2\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Entrenamos los 3 modelos single-output\n",
    "for k, out_name in enumerate(target_cols):\n",
    "    train_single_output_model(k, out_name)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10) SHAP for single-output models (with display feature names)\n",
    "\n",
    "# %%\n",
    "def normalize_single_output_shap(shap_raw, n_features):\n",
    "    if isinstance(shap_raw, (list, tuple)):\n",
    "        if len(shap_raw) == 0:\n",
    "            raise ValueError(\"Empty SHAP result for single-output model.\")\n",
    "        arr = np.array(shap_raw[0])\n",
    "    else:\n",
    "        arr = np.array(shap_raw)\n",
    "    arr = np.squeeze(arr)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr.reshape(-1, n_features)\n",
    "    if arr.shape[1] != n_features:\n",
    "        raise ValueError(f\"Unexpected SHAP shape {arr.shape}, expected {n_features} features\")\n",
    "    return arr\n",
    "\n",
    "n_features = len(clinical_feature_names)\n",
    "single_shap_values = {}\n",
    "\n",
    "for k, out_name in enumerate(target_cols):\n",
    "    print(f\"\\n=== Computing SHAP for single-output model: {out_name} (v2) ===\")\n",
    "    model_k = single_models[out_name]\n",
    "    model_k.eval()\n",
    "\n",
    "    def _compute_shap_single_core():\n",
    "        explainer_k = shap.DeepExplainer(model_k, X_bg_scaled_t)\n",
    "        shap_raw = explainer_k.shap_values(X_exp_scaled_t)\n",
    "        shap_norm = normalize_single_output_shap(shap_raw, n_features=n_features)\n",
    "        return shap_norm\n",
    "\n",
    "    # --- MEDICIÓN DE TIEMPO Y MEMORIA TOTAL (PEAK) EN MB ---\n",
    "    shap_arr, shap_time_single, mem_peak_mb, mem_start_mb, mem_end_mb = profile_stage_total_MB(_compute_shap_single_core, interval=0.05)\n",
    "\n",
    "    print(f\"[SHAP single {out_name}] Time: {shap_time_single:.3f} s\")\n",
    "    print(f\"[SHAP single {out_name}] Memory PEAK: {mem_peak_mb:.2f} MB (start={mem_start_mb:.2f}, end={mem_end_mb:.2f})\")\n",
    "\n",
    "    add_runtime_record(\n",
    "        stage=\"shap_single\",\n",
    "        detail=out_name,\n",
    "        time_sec=shap_time_single,\n",
    "        mem_peak_mb=mem_peak_mb,\n",
    "        mem_start_mb=mem_start_mb,\n",
    "        mem_end_mb=mem_end_mb,\n",
    "    )\n",
    "\n",
    "    # Guardamos en memoria y a disco\n",
    "    single_shap_values[out_name] = shap_arr\n",
    "    np.save(OUT_DIR / f\"shap_values_single_{out_name}_cbc_v2.npy\", shap_arr)\n",
    "\n",
    "with open(OUT_DIR / \"shap_single_meta_cbc_v2.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"mode\": \"single-output-per-target\",\n",
    "        \"method\": \"DeepExplainer\",\n",
    "        \"background_size\": int(X_bg_scaled_t.shape[0]),\n",
    "        \"explain_size\": int(X_exp_scaled_t.shape[0]),\n",
    "        \"targets_raw\": target_cols,\n",
    "        \"targets_display\": target_display_names,\n",
    "        \"n_features_used\": int(X_exp_np.shape[1]),\n",
    "        \"feature_names_raw\": clinical_feature_names,\n",
    "        \"feature_names_display\": clinical_feature_names_display,\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"Saved single-output SHAP arrays (.npy) and metadata (.json) for v2.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 11) SHAP single-output — mean |SHAP|, bar & beeswarm (display names)\n",
    "\n",
    "# %%\n",
    "mean_abs_single = {}\n",
    "for out_name in target_cols:\n",
    "    v = np.abs(single_shap_values[out_name]).mean(axis=0)\n",
    "    s = pd.Series(v, index=clinical_feature_names_display).sort_values(ascending=False)\n",
    "    mean_abs_single[out_name] = s\n",
    "    s.to_csv(\n",
    "        TAB_DIR / f\"mean_abs_shap_single_{out_name}_cbc_v2.csv\",\n",
    "        header=[\"mean_abs_shap\"],\n",
    "        index_label=\"feature_display\",\n",
    "    )\n",
    "\n",
    "combined_single = pd.DataFrame(\n",
    "    {out_name: mean_abs_single[out_name].values for out_name in target_cols},\n",
    "    index=clinical_feature_names_display,\n",
    ")\n",
    "combined_single.to_csv(\n",
    "    TAB_DIR / \"mean_abs_shap_single_all_cbc_v2.csv\",\n",
    "    index_label=\"feature_display\",\n",
    ")\n",
    "\n",
    "print(\"Saved mean |SHAP| tables for single-output models (v2).\")\n",
    "\n",
    "for out_name in target_cols:\n",
    "    out_display = target_display_map.get(out_name, out_name)\n",
    "    s = mean_abs_single[out_name].sort_values(ascending=False)\n",
    "    #top5 = s.head(5)\n",
    "    top5=s.head(10)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(\"white\")\n",
    "    top5[::-1].plot(kind=\"barh\", color=\"#1f77b4\")\n",
    "    plt.title(f\"Top-5 mean |SHAP| — Single-output — {out_display}\")\n",
    "    plt.xlabel(\"Mean |SHAP value|\")\n",
    "    plt.tight_layout()\n",
    "    save_current_fig(IMG_DIR / f\"shap_bar_single_{out_name}_cbc_v2\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    shap.summary_plot(\n",
    "        single_shap_values[out_name],\n",
    "        X_exp_view,\n",
    "        feature_names=clinical_feature_names_display,\n",
    "        max_display=5,\n",
    "        show=False,\n",
    "    )\n",
    "    plt.title(f\"SHAP beeswarm — Single-output — {out_display}\")\n",
    "    plt.tight_layout()\n",
    "    save_current_fig(IMG_DIR / f\"shap_beeswarm_top5_single_{out_name}_cbc_v2\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"Saved Top-5 bar & beeswarm plots for single-output models (v2) with display names.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12) SHAP single-output — heatmap, dependence, cross-output SHAP corr (display)\n",
    "\n",
    "# %%\n",
    "overall_single = combined_single.abs().sum(axis=1).sort_values(ascending=False)\n",
    "topK_single = 10\n",
    "top_features_single = overall_single.head(topK_single).index.tolist()\n",
    "\n",
    "heat_single = combined_single.loc[top_features_single, :].values\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(heat_single, aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(target_display_names)), target_display_names, rotation=0)\n",
    "plt.yticks(range(len(top_features_single)), top_features_single)\n",
    "plt.title(\"Mean |SHAP| (single-output, v2) — Top features vs targets\")\n",
    "plt.tight_layout()\n",
    "save_current_fig(IMG_DIR / \"shap_heatmap_single_top_features_cbc_v2\")\n",
    "plt.show()\n",
    "\n",
    "top1_single_idx = {}\n",
    "for out_name in target_cols:\n",
    "    s = mean_abs_single[out_name]\n",
    "    name_to_idx = {disp: j for j, disp in enumerate(clinical_feature_names_display)}\n",
    "    feat_display = s.index[0]\n",
    "    feat_idx = name_to_idx[feat_display]\n",
    "    top1_single_idx[out_name] = (feat_idx, feat_display)\n",
    "\n",
    "print(\"Top-1 features (single-output, v2):\", {k: v[1] for k, v in top1_single_idx.items()})\n",
    "\n",
    "for out_name in target_cols:\n",
    "    out_display = target_display_map.get(out_name, out_name)\n",
    "    feat_idx, feat_display = top1_single_idx[out_name]\n",
    "\n",
    "    plt.figure()\n",
    "    shap.dependence_plot(\n",
    "        ind=feat_idx,\n",
    "        shap_values=single_shap_values[out_name],\n",
    "        features=X_exp_unscaled,\n",
    "        feature_names=clinical_feature_names_display,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(f\"SHAP dependence — Single-output — {out_display} vs {feat_display}\")\n",
    "    save_current_fig(IMG_DIR / f\"shap_dependence_single_{out_name}_feat{feat_idx}_cbc_v2\")\n",
    "    plt.show()\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "corr_rows_single = []\n",
    "for outA, outB in combinations(target_cols, 2):\n",
    "    svA = single_shap_values[outA]\n",
    "    svB = single_shap_values[outB]\n",
    "\n",
    "    mean_shap_A = pd.Series(svA.mean(axis=0), index=clinical_feature_names_display)\n",
    "    mean_shap_B = pd.Series(svB.mean(axis=0), index=clinical_feature_names_display)\n",
    "    c = mean_shap_A.corr(mean_shap_B)\n",
    "\n",
    "    corr_rows_single.append({\n",
    "        \"output_A_raw\": outA,\n",
    "        \"output_A_display\": target_display_map.get(outA, outA),\n",
    "        \"output_B_raw\": outB,\n",
    "        \"output_B_display\": target_display_map.get(outB, outB),\n",
    "        \"featurewise_SHAP_corr\": float(c)\n",
    "    })\n",
    "\n",
    "corr_df_single = pd.DataFrame(corr_rows_single)\n",
    "corr_df_single.to_csv(\n",
    "    TAB_DIR / \"cross_output_shap_single_featurewise_corr_cbc_v2.csv\",\n",
    "    index=False\n",
    ")\n",
    "print(corr_df_single)\n",
    "print(\"Saved cross-output SHAP correlation CSV for single-output models (v2) with display names.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 13) Output correlations: TRUE vs multi-output vs single-output (display names)\n",
    "\n",
    "# %%\n",
    "print(\"=== Computing correlations among HGB, HCT, RBC (v2) ===\")\n",
    "\n",
    "true_corr = Y_test_df[target_cols].corr()\n",
    "\n",
    "multi_model.eval()\n",
    "with torch.no_grad():\n",
    "    preds_multi_std = multi_model(\n",
    "        torch.tensor(X_test_scaled, dtype=torch.float32, device=device)\n",
    "    ).cpu().numpy()\n",
    "preds_multi = preds_multi_std * scaler_Y.scale_ + scaler_Y.mean_\n",
    "preds_multi_df = pd.DataFrame(preds_multi, columns=target_cols)\n",
    "multi_corr = preds_multi_df.corr()\n",
    "\n",
    "preds_single_dict = {}\n",
    "for k, out_name in enumerate(target_cols):\n",
    "    model_k = single_models[out_name]\n",
    "    model_k.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_std = model_k(\n",
    "            torch.tensor(X_test_scaled, dtype=torch.float32, device=device)\n",
    "        ).cpu().numpy().reshape(-1)\n",
    "    preds_single_dict[out_name] = pred_std * scaler_Y.scale_[k] + scaler_Y.mean_[k]\n",
    "\n",
    "preds_single_df = pd.DataFrame(preds_single_dict)\n",
    "single_corr = preds_single_df.corr()\n",
    "\n",
    "true_corr.to_csv(TAB_DIR / \"corr_true_outputs_cbc_v2_test.csv\", index_label=\"target_raw\")\n",
    "multi_corr.to_csv(TAB_DIR / \"corr_multi_output_preds_cbc_v2_test.csv\", index_label=\"target_raw\")\n",
    "single_corr.to_csv(TAB_DIR / \"corr_single_output_preds_cbc_v2_test.csv\", index_label=\"target_raw\")\n",
    "\n",
    "print(\"True correlation:\\n\", true_corr)\n",
    "print(\"\\nMulti-output preds correlation:\\n\", multi_corr)\n",
    "print(\"\\nSingle-output preds correlation:\\n\", single_corr)\n",
    "\n",
    "def plot_corr_heatmap(mat, title, filename):\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.imshow(mat, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(len(target_display_names)), target_display_names)\n",
    "    plt.yticks(range(len(target_display_names)), target_display_names)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    save_current_fig(IMG_DIR / filename)\n",
    "    plt.show()\n",
    "\n",
    "plot_corr_heatmap(true_corr.values,\n",
    "                  \"Correlation — TRUE outputs (test, v2)\",\n",
    "                  \"corr_heatmap_true_outputs_cbc_v2_test\")\n",
    "\n",
    "plot_corr_heatmap(multi_corr.values,\n",
    "                  \"Correlation — MULTI-OUTPUT predictions (test, v2)\",\n",
    "                  \"corr_heatmap_multi_output_preds_cbc_v2_test\")\n",
    "\n",
    "plot_corr_heatmap(single_corr.values,\n",
    "                  \"Correlation — SINGLE-OUTPUT predictions (test, v2)\",\n",
    "                  \"corr_heatmap_single_output_preds_cbc_v2_test\")\n",
    "\n",
    "print(\"\\n=== Done! Correlation matrices and heatmaps saved successfully (v2). ===\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 14) Save runtime & memory summary (MB)\n",
    "\n",
    "# %%\n",
    "runtime_df = pd.DataFrame(runtime_records)\n",
    "\n",
    "csv_path = TAB_DIR / \"runtime_memory_cbc_v2_MB.csv\"\n",
    "runtime_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"\\n=== Runtime & Memory summary saved ===\")\n",
    "print(\"Path:\", csv_path)\n",
    "print(runtime_df)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 15) Evaluation metrics for Multi-output and Single-output Models (Train / Val / Test)\n",
    "\n",
    "# %%\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "Y_train_real = Y_train\n",
    "Y_val_real   = Y_val\n",
    "Y_test_real  = Y_test\n",
    "\n",
    "multi_model.eval()\n",
    "\n",
    "def eval_multi_split(split_name, X_scaled, Y_real):\n",
    "    with torch.no_grad():\n",
    "        preds_scaled = multi_model(\n",
    "            torch.tensor(X_scaled, dtype=torch.float32, device=device)\n",
    "        ).cpu().numpy()\n",
    "\n",
    "    preds_real = scaler_Y.inverse_transform(preds_scaled)\n",
    "\n",
    "    rows = []\n",
    "    for j, out_name in enumerate(target_cols):\n",
    "        out_display = target_display_map.get(out_name, out_name)\n",
    "\n",
    "        y_true = Y_real[:, j]\n",
    "        y_pred = preds_real[:, j]\n",
    "\n",
    "        r2   = r2_score(y_true, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mae  = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "        median_thr = np.median(y_true)\n",
    "        y_true_bin = (y_true > median_thr).astype(int)\n",
    "        y_pred_bin = (y_pred > median_thr).astype(int)\n",
    "        f1 = f1_score(y_true_bin, y_pred_bin)\n",
    "\n",
    "        rows.append({\n",
    "            \"model_type\": \"multi-output\",\n",
    "            \"split\": split_name,\n",
    "            \"output\": out_display,\n",
    "            \"R2\": r2,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"F1_median\": f1,\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "metrics_multi_all = []\n",
    "metrics_multi_all += eval_multi_split(\"train\", X_train_scaled, Y_train_real)\n",
    "metrics_multi_all += eval_multi_split(\"val\",   X_val_scaled,   Y_val_real)\n",
    "metrics_multi_all += eval_multi_split(\"test\",  X_test_scaled,  Y_test_real)\n",
    "\n",
    "df_metrics_multi_all = pd.DataFrame(metrics_multi_all)\n",
    "df_metrics_multi_all.to_csv(\n",
    "    TAB_DIR / \"metrics_multi_output_all_splits_cbc_v2.csv\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "print(\"Multi-output metrics (train/val/test):\")\n",
    "display(df_metrics_multi_all)\n",
    "\n",
    "\n",
    "def eval_single_split(split_name, X_scaled, Y_real):\n",
    "    rows = []\n",
    "    for k, out_name in enumerate(target_cols):\n",
    "        out_display = target_display_map.get(out_name, out_name)\n",
    "\n",
    "        model_k = single_models[out_name]\n",
    "        model_k.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds_k_scaled = model_k(\n",
    "                torch.tensor(X_scaled, dtype=torch.float32, device=device)\n",
    "            ).cpu().numpy()   # shape (n_samples, 1)\n",
    "\n",
    "        repeated = np.repeat(preds_k_scaled, repeats=len(target_cols), axis=1)\n",
    "        preds_k_real = scaler_Y.inverse_transform(repeated)[:, k]\n",
    "\n",
    "        y_true_k = Y_real[:, k]\n",
    "\n",
    "        r2_k   = r2_score(y_true_k, preds_k_real)\n",
    "        rmse_k = np.sqrt(mean_squared_error(y_true_k, preds_k_real))\n",
    "        mae_k  = mean_absolute_error(y_true_k, preds_k_real)\n",
    "\n",
    "        median_thr = np.median(y_true_k)\n",
    "        y_true_bin = (y_true_k > median_thr).astype(int)\n",
    "        y_pred_bin = (preds_k_real > median_thr).astype(int)\n",
    "        f1_k = f1_score(y_true_bin, y_pred_bin)\n",
    "\n",
    "        rows.append({\n",
    "            \"model_type\": \"single-output\",\n",
    "            \"split\": split_name,\n",
    "            \"output\": out_display,\n",
    "            \"R2\": r2_k,\n",
    "            \"RMSE\": rmse_k,\n",
    "            \"MAE\": mae_k,\n",
    "            \"F1_median\": f1_k,\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "metrics_single_all = []\n",
    "metrics_single_all += eval_single_split(\"train\", X_train_scaled, Y_train_real)\n",
    "metrics_single_all += eval_single_split(\"val\",   X_val_scaled,   Y_val_real)\n",
    "metrics_single_all += eval_single_split(\"test\",  X_test_scaled,  Y_test_real)\n",
    "\n",
    "df_metrics_single_all = pd.DataFrame(metrics_single_all)\n",
    "df_metrics_single_all.to_csv(\n",
    "    TAB_DIR / \"metrics_single_output_all_splits_cbc_v2.csv\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "print(\"Single-output metrics (train/val/test):\")\n",
    "display(df_metrics_single_all)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 16) Redesigned Figures (with custom font sizes)\n",
    "#\n",
    "# - (A) Bar comparison (Multi vs Single) with consistent colors\n",
    "# - (B) Raw SHAP side-by-side beeswarms (Multi vs Single)\n",
    "# - Customizable font sizes for titles/axes/ticks/legend\n",
    "\n",
    "# %%\n",
    "# --- Safety checks: ensure required variables exist ---\n",
    "required_vars = [\n",
    "    \"target_cols\",\n",
    "    \"target_display_map\",\n",
    "    \"clinical_feature_names_display\",\n",
    "    \"X_exp_unscaled\",\n",
    "    \"shap_values_per_output\",\n",
    "    \"single_shap_values\",\n",
    "    \"IMG_DIR\",\n",
    "    \"save_current_fig\",\n",
    "]\n",
    "missing = [v for v in required_vars if v not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Missing variables needed for redesigned figures: {missing}\")\n",
    "\n",
    "# -----------------------------\n",
    "# User-configurable parameters\n",
    "# -----------------------------\n",
    "TOPK = 10  # number of features to display per output in redesigned plots\n",
    "\n",
    "# Consistent colors across all outputs:\n",
    "COLOR_MULTI  = \"#1f77b4\"  # blue\n",
    "COLOR_SINGLE = \"#ff7f0e\"  # orange\n",
    "\n",
    "# -----------------------------\n",
    "# Font sizes (customize here)\n",
    "# -----------------------------\n",
    "FS_TITLE = 18\n",
    "FS_LABEL = 16\n",
    "FS_TICK  = 16\n",
    "FS_LEG   = 13\n",
    "\n",
    "# Optional: apply globally to matplotlib (affects all plots created after this)\n",
    "plt.rcParams.update({\n",
    "    \"axes.titlesize\": FS_TITLE,\n",
    "    \"axes.labelsize\": FS_LABEL,\n",
    "    \"xtick.labelsize\": FS_TICK,\n",
    "    \"ytick.labelsize\": FS_TICK,\n",
    "    \"legend.fontsize\": FS_LEG,\n",
    "})\n",
    "\n",
    "# Helper: mean(|SHAP|) as pandas.Series indexed by display feature names\n",
    "def mean_abs_series(shap_array, feature_names_display):\n",
    "    return pd.Series(np.mean(np.abs(shap_array), axis=0), index=feature_names_display)\n",
    "\n",
    "# ============================================================\n",
    "# Figure A: Side-by-side barplots (Multi vs Single) per output\n",
    "# ============================================================\n",
    "for out_idx, out_name in enumerate(target_cols):\n",
    "    out_disp = target_display_map.get(out_name, out_name)\n",
    "\n",
    "    # Multi and Single mean(|SHAP|)\n",
    "    s_multi  = mean_abs_series(shap_values_per_output[out_idx], clinical_feature_names_display)\n",
    "    s_single = mean_abs_series(single_shap_values[out_name],      clinical_feature_names_display)\n",
    "\n",
    "    # Use a common TopK based on combined importance (to align bars)\n",
    "    s_combined = (s_multi + s_single).sort_values(ascending=False)\n",
    "    top_feats = s_combined.head(TOPK).index.tolist()\n",
    "\n",
    "    df_bar = pd.DataFrame({\n",
    "        \"Multi-output\":  s_multi.loc[top_feats].values,\n",
    "        \"Single-output\": s_single.loc[top_feats].values,\n",
    "    }, index=top_feats)\n",
    "\n",
    "    # Plot grouped horizontal bars\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(\"white\")\n",
    "\n",
    "    y = np.arange(len(top_feats))\n",
    "    h = 0.38\n",
    "\n",
    "    ax.barh(y - h/2, df_bar[\"Multi-output\"],  height=h, color=COLOR_MULTI,  label=\"Multi-output\")\n",
    "    ax.barh(y + h/2, df_bar[\"Single-output\"], height=h, color=COLOR_SINGLE, label=\"Single-output\")\n",
    "\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(top_feats, fontsize=FS_TICK)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set_xlabel(\"Mean |SHAP value|\", fontsize=FS_LABEL)\n",
    "    #ax.set_title(f\"Top-{TOPK} mean |SHAP| comparison — {out_disp}\", fontsize=FS_TITLE)\n",
    "\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=FS_TICK)\n",
    "    ax.legend(loc=\"lower right\", fontsize=FS_LEG)\n",
    "\n",
    "    # If labels get clipped, increase left margin\n",
    "    plt.tight_layout()\n",
    "    # Alternatively, uncomment and adjust:\n",
    "    # plt.subplots_adjust(left=0.30, right=0.98, top=0.90, bottom=0.12)\n",
    "\n",
    "    save_current_fig(IMG_DIR / f\"redesign_bar_compare_multi_vs_single_{out_idx}_top{TOPK}_cbc_v2\")\n",
    "    plt.show()\n",
    "    plt.close() \n",
    "\n",
    "print(f\"Saved redesigned BAR comparison plots (Top-{TOPK}) for all outputs.\")\n",
    "\n",
    "# ============================================================\n",
    "# Figure B: Raw SHAP side-by-side beeswarms (Multi vs Single)\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "for out_idx, out_name in enumerate(target_cols):\n",
    "    out_disp = target_display_map.get(out_name, out_name)\n",
    "\n",
    "    sv_multi  = shap_values_per_output[out_idx]     # (n_samples, n_features)\n",
    "    sv_single = single_shap_values[out_name]        # (n_samples, n_features)\n",
    "\n",
    "    s_multi  = mean_abs_series(sv_multi,  clinical_feature_names_display)\n",
    "    s_single = mean_abs_series(sv_single, clinical_feature_names_display)\n",
    "\n",
    "    # Same TopK subset for both (based on combined importance)\n",
    "    top_feats = (s_multi + s_single).sort_values(ascending=False).head(TOPK).index.tolist()\n",
    "    feat_to_idx = {name: j for j, name in enumerate(clinical_feature_names_display)}\n",
    "    top_idx = [feat_to_idx[f] for f in top_feats]\n",
    "\n",
    "    sv_multi_sub  = sv_multi[:,  top_idx]\n",
    "    sv_single_sub = sv_single[:, top_idx]\n",
    "\n",
    "    # Use the same feature values subset\n",
    "    X_sub = X_exp_unscaled.values[:, top_idx]\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 6))\n",
    "    gs = fig.add_gridspec(1, 2, wspace=0.30)\n",
    "\n",
    "    # Left: Multi-output raw SHAP\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    plt.sca(ax1)\n",
    "    shap.summary_plot(\n",
    "        sv_multi_sub,\n",
    "        features=X_sub,\n",
    "        feature_names=top_feats,\n",
    "        max_display=TOPK,\n",
    "        show=False,\n",
    "    )\n",
    "    ax1 = plt.gca()\n",
    "    ax1.set_title(f\"Raw SHAP (beeswarm) — Multi-output — {out_disp}\", fontsize=FS_TITLE)\n",
    "    ax1.tick_params(axis=\"both\", which=\"major\", labelsize=FS_TICK)\n",
    "    ax1.set_xlabel(ax1.get_xlabel(), fontsize=FS_LABEL)\n",
    "    ax1.set_ylabel(ax1.get_ylabel(), fontsize=FS_LABEL)\n",
    "\n",
    "    # Right: Single-output raw SHAP\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    plt.sca(ax2)\n",
    "    shap.summary_plot(\n",
    "        sv_single_sub,\n",
    "        features=X_sub,\n",
    "        feature_names=top_feats,\n",
    "        max_display=TOPK,\n",
    "        show=False,\n",
    "    )\n",
    "    ax2 = plt.gca()\n",
    "    ax2.set_title(f\"Raw SHAP (beeswarm) — Single-output — {out_disp}\", fontsize=FS_TITLE)\n",
    "    ax2.tick_params(axis=\"both\", which=\"major\", labelsize=FS_TICK)\n",
    "    ax2.set_xlabel(ax2.get_xlabel(), fontsize=FS_LABEL)\n",
    "    ax2.set_ylabel(ax2.get_ylabel(), fontsize=FS_LABEL)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # If labels get clipped, increase margins:\n",
    "    # plt.subplots_adjust(left=0.25, right=0.98, top=0.90, bottom=0.15, wspace=0.35)\n",
    "\n",
    "    save_current_fig(IMG_DIR / f\"redesign_beeswarm_compare_multi_vs_single_{out_name}_top{TOPK}_cbc_v2\")\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "#print(f\"Saved redesigned SIDE-BY-SIDE beeswarm (raw SHAP) plots (Top-{TOPK}) for all outputs.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 17) Quantitative similarity of raw SHAP values\n",
    "# ##\n",
    "# # - Cosine similarity (per output)\n",
    "# # - Spearman rank correlation (per output)\n",
    "# # - Computed on RAW SHAP values (instance-wise, feature-wise)\n",
    "# # - Results saved as CSV for manuscript reporting\n",
    "\n",
    "# %%\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def cosine_similarity(vec_a, vec_b, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two 1D vectors.\n",
    "    \"\"\"\n",
    "    num = np.dot(vec_a, vec_b)\n",
    "    den = (np.linalg.norm(vec_a) * np.linalg.norm(vec_b)) + eps\n",
    "    return float(num / den)\n",
    "\n",
    "similarity_rows = []\n",
    "\n",
    "for k, out_name in enumerate(target_cols):\n",
    "    out_display = target_display_map.get(out_name, out_name)\n",
    "\n",
    "    # --- RAW SHAP arrays ---\n",
    "    # Multi-output: shap_values_per_output[k] -> (n_samples, n_features)\n",
    "    # Single-output: single_shap_values[out_name] -> (n_samples, n_features)\n",
    "    shap_multi  = shap_values_per_output[k]\n",
    "    shap_single = single_shap_values[out_name]\n",
    "\n",
    "    # Safety check\n",
    "    if shap_multi.shape != shap_single.shape:\n",
    "        raise ValueError(\n",
    "            f\"Shape mismatch for output {out_name}: \"\n",
    "            f\"multi {shap_multi.shape}, single {shap_single.shape}\"\n",
    "        )\n",
    "\n",
    "    # Vectorize (instance-wise + feature-wise)\n",
    "    vec_multi  = shap_multi.reshape(-1)\n",
    "    vec_single = shap_single.reshape(-1)\n",
    "\n",
    "    # --- Cosine similarity ---\n",
    "    cos_sim = cosine_similarity(vec_multi, vec_single)\n",
    "\n",
    "    # --- Spearman rank correlation ---\n",
    "    spearman_corr, spearman_p = spearmanr(vec_multi, vec_single)\n",
    "\n",
    "    similarity_rows.append({\n",
    "        \"output_raw\": out_name,\n",
    "        \"output_display\": out_display,\n",
    "        \"n_samples\": shap_multi.shape[0],\n",
    "        \"n_features\": shap_multi.shape[1],\n",
    "        \"cosine_similarity\": cos_sim,\n",
    "        \"spearman_correlation\": float(spearman_corr),\n",
    "        \"spearman_pvalue\": float(spearman_p),\n",
    "    })\n",
    "\n",
    "# Build DataFrame\n",
    "similarity_df = pd.DataFrame(similarity_rows)\n",
    "\n",
    "# Save per-output similarities\n",
    "csv_path = TAB_DIR / \"shap_local_similarity_multi_vs_single_cbc_v2.csv\"\n",
    "similarity_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"\\n=== Local SHAP similarity (multi vs single) — per output ===\")\n",
    "print(similarity_df)\n",
    "print(f\"\\nSaved SHAP similarity metrics to:\\n{csv_path}\")\n",
    "\n",
    "# --- Optional: also save a compact summary (mean ± std across outputs) ---\n",
    "summary_df = pd.DataFrame({\n",
    "    \"metric\": [\"cosine_similarity\", \"spearman_correlation\"],\n",
    "    \"mean\": [\n",
    "        similarity_df[\"cosine_similarity\"].mean(),\n",
    "        similarity_df[\"spearman_correlation\"].mean(),\n",
    "    ],\n",
    "    \"std\": [\n",
    "        similarity_df[\"cosine_similarity\"].std(ddof=1),\n",
    "        similarity_df[\"spearman_correlation\"].std(ddof=1),\n",
    "    ],\n",
    "})\n",
    "\n",
    "summary_path = TAB_DIR / \"shap_local_similarity_summary_multi_vs_single_cbc_v2.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "\n",
    "print(\"\\n=== Summary across outputs (mean ± std) ===\")\n",
    "print(summary_df)\n",
    "print(f\"\\nSaved summary to:\\n{summary_path}\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 18) Local SHAP similarity restricted to Top-5 features (per output)\n",
    "# #\n",
    "# # - Top-5 features selected per output based on combined mean |SHAP|\n",
    "# #   (multi-output + single-output)\n",
    "# # - Cosine similarity and Spearman correlation computed on RAW SHAP values\n",
    "# # - Metrics computed separately for each output\n",
    "# # - Results saved as CSV\n",
    "\n",
    "# %%\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def cosine_similarity(vec_a, vec_b, eps=1e-12):\n",
    "    num = np.dot(vec_a, vec_b)\n",
    "    den = (np.linalg.norm(vec_a) * np.linalg.norm(vec_b)) + eps\n",
    "    return float(num / den)\n",
    "\n",
    "topK = 10\n",
    "similarity_topk_rows = []\n",
    "\n",
    "# Precompute feature index mapping (display name -> index)\n",
    "feat_to_idx = {name: j for j, name in enumerate(clinical_feature_names_display)}\n",
    "\n",
    "for k, out_name in enumerate(target_cols):\n",
    "    out_display = target_display_map.get(out_name, out_name)\n",
    "\n",
    "    # --- Raw SHAP arrays ---\n",
    "    shap_multi  = shap_values_per_output[k]          # (n_samples, n_features)\n",
    "    shap_single = single_shap_values[out_name]       # (n_samples, n_features)\n",
    "\n",
    "    # --- Mean |SHAP| per feature ---\n",
    "    mean_multi  = np.mean(np.abs(shap_multi),  axis=0)\n",
    "    mean_single = np.mean(np.abs(shap_single), axis=0)\n",
    "\n",
    "    # Combined importance to define Top-5 consistently\n",
    "    combined_importance = mean_multi + mean_single\n",
    "    topk_idx = np.argsort(combined_importance)[::-1][:topK]\n",
    "\n",
    "    topk_features_display = [clinical_feature_names_display[j] for j in topk_idx]\n",
    "\n",
    "    # --- Restrict SHAP arrays to Top-5 features ---\n",
    "    shap_multi_topk  = shap_multi[:,  topk_idx]\n",
    "    shap_single_topk = shap_single[:, topk_idx]\n",
    "\n",
    "    # Vectorize\n",
    "    vec_multi  = shap_multi_topk.reshape(-1)\n",
    "    vec_single = shap_single_topk.reshape(-1)\n",
    "\n",
    "    # --- Similarity metrics ---\n",
    "    cos_sim = cosine_similarity(vec_multi, vec_single)\n",
    "    spearman_corr, spearman_p = spearmanr(vec_multi, vec_single)\n",
    "\n",
    "    similarity_topk_rows.append({\n",
    "        \"output_raw\": out_name,\n",
    "        \"output_display\": out_display,\n",
    "        \"topK\": topK,\n",
    "        \"topK_features_display\": \"; \".join(topk_features_display),\n",
    "        \"n_samples\": shap_multi_topk.shape[0],\n",
    "        \"cosine_similarity_topK\": cos_sim,\n",
    "        \"spearman_correlation_topK\": float(spearman_corr),\n",
    "        \"spearman_pvalue_topK\": float(spearman_p),\n",
    "    })\n",
    "\n",
    "# Build DataFrame\n",
    "similarity_topk_df = pd.DataFrame(similarity_topk_rows)\n",
    "\n",
    "# Save per-output Top-K similarities\n",
    "csv_path = TAB_DIR / \"shap_local_similarity_top5_multi_vs_single_cbc_v2.csv\"\n",
    "similarity_topk_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"\\n=== Local SHAP similarity (Top-5 features, multi vs single) ===\")\n",
    "print(similarity_topk_df)\n",
    "print(f\"\\nSaved Top-5 SHAP similarity metrics to:\\n{csv_path}\")\n",
    "\n",
    "# --- Optional: summary across outputs ---\n",
    "summary_topk_df = pd.DataFrame({\n",
    "    \"metric\": [\"cosine_similarity_topK\", \"spearman_correlation_topK\"],\n",
    "    \"mean\": [\n",
    "        similarity_topk_df[\"cosine_similarity_topK\"].mean(),\n",
    "        similarity_topk_df[\"spearman_correlation_topK\"].mean(),\n",
    "    ],\n",
    "    \"std\": [\n",
    "        similarity_topk_df[\"cosine_similarity_topK\"].std(ddof=1),\n",
    "        similarity_topk_df[\"spearman_correlation_topK\"].std(ddof=1),\n",
    "    ],\n",
    "})\n",
    "\n",
    "summary_path = TAB_DIR / \"shap_local_similarity_top5_summary_multi_vs_single_cbc_v2.csv\"\n",
    "summary_topk_df.to_csv(summary_path, index=False)\n",
    "\n",
    "print(\"\\n=== Top-5 summary across outputs (mean ± std) ===\")\n",
    "print(summary_topk_df)\n",
    "print(f\"\\nSaved Top-5 summary to:\\n{summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce2003c-be50-4e56-acc2-b35a8059ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 19) Combined figure: Top-5 mean |SHAP| (Multi vs Single) for all outputs\n",
    "\n",
    "# %%\n",
    "print(\"\\n[FIG19] Starting combined TopK mean|SHAP| figure...\")\n",
    "\n",
    "# --- Quick diagnostics (do NOT crash) ---\n",
    "diag_vars = [\n",
    "    \"target_cols\",\n",
    "    \"target_display_map\",\n",
    "    \"clinical_feature_names_display\",\n",
    "    \"shap_values_per_output\",\n",
    "    \"single_shap_values\",\n",
    "    \"IMG_DIR\",\n",
    "    \"save_current_fig\",\n",
    "    \"TOPK\",\n",
    "]\n",
    "for v in diag_vars:\n",
    "    print(f\"[FIG19] {v} in globals? ->\", v in globals())\n",
    "\n",
    "# Fallbacks if some style vars are missing\n",
    "TOPK = globals().get(\"TOPK\", 5)\n",
    "COLOR_MULTI  = globals().get(\"COLOR_MULTI\",  \"#1f77b4\")\n",
    "COLOR_SINGLE = globals().get(\"COLOR_SINGLE\", \"#ff7f0e\")\n",
    "FS_TITLE = globals().get(\"FS_TITLE\", 16)\n",
    "FS_LABEL = globals().get(\"FS_LABEL\", 14)\n",
    "FS_TICK  = globals().get(\"FS_TICK\",  12)\n",
    "FS_LEG   = globals().get(\"FS_LEG\",   12)\n",
    "\n",
    "print(f\"[FIG19] Using TOPK={TOPK}\")\n",
    "\n",
    "# --- Define helper (local) ---\n",
    "def _mean_abs_series(shap_array, feature_names_display):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    return pd.Series(np.mean(np.abs(shap_array), axis=0), index=feature_names_display)\n",
    "\n",
    "# --- Assert minimally required data (fail with clear message) ---\n",
    "assert \"target_cols\" in globals() and len(target_cols) > 0, \"[FIG19] target_cols missing/empty.\"\n",
    "assert \"clinical_feature_names_display\" in globals(), \"[FIG19] clinical_feature_names_display missing.\"\n",
    "assert \"shap_values_per_output\" in globals(), \"[FIG19] shap_values_per_output missing.\"\n",
    "assert \"single_shap_values\" in globals(), \"[FIG19] single_shap_values missing.\"\n",
    "assert \"IMG_DIR\" in globals(), \"[FIG19] IMG_DIR missing.\"\n",
    "assert \"save_current_fig\" in globals(), \"[FIG19] save_current_fig missing.\"\n",
    "\n",
    "print(\"[FIG19] Basic inputs OK.\")\n",
    "print(\"[FIG19] n_outputs =\", len(target_cols))\n",
    "print(\"[FIG19] n_features_display =\", len(clinical_feature_names_display))\n",
    "print(\"[FIG19] shap_values_per_output lens =\", len(shap_values_per_output))\n",
    "print(\"[FIG19] single_shap_values keys =\", list(single_shap_values.keys()))\n",
    "\n",
    "# --- Build the combined figure ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, len(target_cols), figsize=(20, 6), constrained_layout=True)\n",
    "if len(target_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "bar_width = 0.38\n",
    "\n",
    "for out_idx, out_name in enumerate(target_cols):\n",
    "    ax = axes[out_idx]\n",
    "    out_disp = target_display_map.get(out_name, out_name) if \"target_display_map\" in globals() else out_name\n",
    "\n",
    "    # Mean(|SHAP|) for multi and single\n",
    "    s_multi  = _mean_abs_series(shap_values_per_output[out_idx], clinical_feature_names_display)\n",
    "    s_single = _mean_abs_series(single_shap_values[out_name],     clinical_feature_names_display)\n",
    "\n",
    "    # Common TopK based on combined importance\n",
    "    s_combined = (s_multi + s_single).sort_values(ascending=False)\n",
    "    top_feats = s_combined.head(TOPK).index.tolist()\n",
    "\n",
    "    y_multi  = s_multi.loc[top_feats].values\n",
    "    y_single = s_single.loc[top_feats].values\n",
    "\n",
    "    x = np.arange(len(top_feats))\n",
    "\n",
    "    ax.bar(x - bar_width/2, y_multi,  width=bar_width, color=COLOR_MULTI,  label=\"Multi-output\")\n",
    "    ax.bar(x + bar_width/2, y_single, width=bar_width, color=COLOR_SINGLE, label=\"Single-output\")\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(top_feats, rotation=90, ha=\"center\", fontsize=FS_TICK)\n",
    "\n",
    "    if out_idx == 0:\n",
    "        ax.set_ylabel(\"Mean |SHAP value|\", fontsize=FS_LABEL)\n",
    "\n",
    "    ax.set_title(out_disp, fontsize=FS_TITLE)\n",
    "    ax.tick_params(axis=\"y\", labelsize=FS_TICK)\n",
    "    ax.grid(axis=\"y\", alpha=0.25)\n",
    "\n",
    "# One legend for whole figure\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"lower center\", ncol=2, fontsize=FS_LEG, frameon=True)\n",
    "\n",
    "# Make room for 90° labels + legend\n",
    "plt.subplots_adjust(bottom=0.30)\n",
    "\n",
    "out_path = IMG_DIR / f\"combined_top{TOPK}_bar_mean_abs_shap_multi_vs_single_all_outputs_cbc_v2\"\n",
    "save_current_fig(out_path)\n",
    "\n",
    "print(f\"[FIG19] Saved figure to: {out_path.with_suffix('.png')} and {out_path.with_suffix('.pdf')}\")\n",
    "\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"[FIG19] Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c18d6a5-b531-4862-9b0d-128139818ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (stroke-mlp2)",
   "language": "python",
   "name": "stroke-mlp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
